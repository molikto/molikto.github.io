<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <title>mathematics</title>
        <link rel="stylesheet" type="text/css" href="./css/snailya.css" />
    </head>
    <body>
    <script src="./js/jquery.min.js"></script>

    <div class="navbar navbar-default" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="./">snailya</a>
        </div>
        <div class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li><a href="./scope.html">scope</a></li>
            <li><a href="./mathematics.html">mathematics</a></li>
            <li class="dropdown">
                <a href="#" class="dropdown-toggle" data-toggle="dropdown">random notes <b class="caret"></b></a>
                <ul class="dropdown-menu">
                
                    <li><a href="./random-notes/pl-ideas.html">pl-ideas</a></li>
                
                    <li><a href="./random-notes/yhbkj.html">yhbkj</a></li>
                
                </ul>
            </li>
            <li><a href="./posts.html">posts</a></li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
            <li><a href="https://github.com/molikto">github</a></li> 
            <li><a href="http://www.douban.com/people/66654255/">douban</a></li>
            <li><a href="./calendar.html">calendar</a></li>
          </ul>
        </div>
      </div>
    </div>
  <div class="body small-container" id="content">
    
<script>
$("#content").css("max-width", "1100px")
</script>


<div class="row">
    <div class="bs-docs-container">
        <div class="col-md-3">
            <div class="bs-docs-sidebar hidden-print" role="complementary">
            </div>
        </div>
    </div>
    <div class="col-md-8">
        <h1 id="type">type</h1>
<h2 id="idea">idea</h2>
<p><a href="#cross-type-theory">type theory</a> is the underlaying logic of mathematical theory</p>
<h3 id="state-of-art">state of art</h3>
<p>actually there are only two main things in the way for adopting <a href="#cross-hott">hott</a> as a working foundation:</p>
<ul>
<li>general <a href="#cross-hit">hit</a></li>
<li><a href="#cross-computation">computation</a> rule for <span class="math">\(J\)</span> for <a href="#cross-higher-inductive-type">higher inductive type</a> and <a href="#cross-univalence-axiom">univalence axiom</a></li>
</ul>
<p>but as i already has an mental model for what the type theory is, and i think it is good enough to just make it here and study classical math using the mental foundation rather than set theory</p>
<p>and one important thing is, when studying the <span class="math">\(Id_A\)</span> structure, you should have a clear view what it is like</p>
<p>so: <strong>we take type theory as implicit foundation for our study</strong>, there are sometimes useful to think higher groups and higher categories, but we can always study them in a classical setting and then translate into <a href="#cross-hott">hott</a></p>
<h2 id="definition">definition</h2>
<ul>
<li><span><span id="cross-type"></span><span id="cross-hott"></span><span id="cross-type-theory" class="crosslink">type theory</span></span>
<ul>
<li><span id="cross-judgment" class="crosslink">judgment</span>
<ul>
<li><span class="math">\(\Gamma ctx\)</span></li>
<li><span class="math">\(\Gamma\vdash a: A\)</span></li>
<li><span class="math">\(\Gamma a\equiv a': A\)</span></li>
</ul></li>
<li><span id="cross-inference-rule" class="crosslink">inference rule</span>
<ul>
<li><span id="cross-type-rule" class="crosslink">type rule</span></li>
<li><span id="cross-introduction-rule" class="crosslink">introduction rule</span></li>
<li><span id="cross-elimination-rule" class="crosslink">elimination rule</span></li>
<li><span><span id="cross-computation"></span><span id="cross-computation-rule" class="crosslink">computation rule</span></span></li>
</ul></li>
<li><span id="cross-derivation" class="crosslink">derivation</span></li>
<li>types
<ul>
<li><span id="cross-universe" class="crosslink">universe</span> <span class="math">\(\mathscr{U}\)</span></li>
<li><span id="cross-function" class="crosslink">function</span></li>
<li><span id="cross-identity-type" class="crosslink">identity type</span>, <span id="cross-reflection" class="crosslink">reflection</span> <span class="math">\({\text{refl}}\)</span>
<ul>
<li><code>open problem</code> how to <span class="math">\(J\)</span> compute with <a href="#cross-univalence-axiom">univalence axiom</a>?</li>
</ul></li>
<li><span><span id="cross-higher-inductive-type"></span><span id="cross-hit"></span><span id="cross-inductive-type" class="crosslink">inductive type</span></span>
<ul>
<li><span><span id="cross-W-type"></span><span id="cross-inductive-type" class="crosslink">inductive type</span></span></li>
<li><code>open problem</code> formalize <a href="#cross-hit">hit</a> it like <a href="#cross-W-type">W-type</a></li>
</ul></li>
<li><span id="cross-univalence-axiom" class="crosslink">univalence axiom</span></li>
</ul></li>
</ul></li>
</ul>
<p><em>most rules see <a href="#cross-ref-hott">ref-hott</a> appendix 2</em></p>
<h2 id="random">random</h2>
<p>set theory is static, it just presents the function as the result, and the <span class="math">\(Nat\)</span> as result. but in type theory, it is not the case</p>
<p>one interesting case is function extensionality, which is implied by univalence axiom, which i believe is good, the functions will be equal not just equal, but there is more in here. if we see the fact that it is implied by univalence, then we should inspect why univalence is true, and also, are all <span class="math">\(id\)</span> is freely generated? because we have three source to generate <span class="math">\(id\)</span>, in higher inductive type and in univalence, they are one for <span class="math">\(=_A\)</span> and one for <span class="math">\(=_\mathcal{U}\)</span>, so we are ok here.</p>
<p>one more issue, if we have a good system to do mathematics in computer, then we should have a pretty printer for as but much cleaver, because machines now understand what we are talking about and can give us much more help</p>
<p>remember in set theory, we also have things like universe, it is the class and set structure, but i think the universe idea is more elegent~</p>
<h3 id="syntax-for-inductive-type-and-higher-inductive-type">syntax for inductive type and higher inductive type</h3>
<ul>
<li>it is possible to think that parameterized inductive type actually brings nothing new, it is just a convenient notation?</li>
<li>the truth is in the inductor, because when you apply a match, you should always be careful how you use them, and this is protected by the inductor (?)</li>
<li>for general inductive type, the constructor do not depend on previous constructors, but for higher inductive type, this is inevitable.</li>
<li>so in ordinary mathematics, the notation of function is collapsed, but in hott, we have a better structure, but why? this seems very unreasonable</li>
<li>the thing is all about we can identify more things, we do this not by making things just equal, i.e. like in ETT and set theory, we forget things, but by equivalences, we identify things and as long as we are not caring what the id results in, i.e. in the type checker level, we just have more power, because we can identify more things equal</li>
<li>in type theory, the notation of equal is by <span class="math">\(X=Y: \forall x(x\in X \Leftrightarrow x\in Y)\)</span>, but in HoTT, all equal is freely generated, although the <span class="math">\(J\)</span> is wired</li>
<li>i still do not understand why type theory</li>
<li><p>the thing is always how are you going to define the inductor.</p></li>
<li><p><span class="math">\(J\)</span> hold but not <span class="math">\(UIP\)</span> <a href="http://homotopytypetheory.org/2011/04/10/just-kidding-understanding-identity-elimination-in-homotopy-type-theory">http://homotopytypetheory.org/2011/04/10/just-kidding-understanding-identity-elimination-in-homotopy-type-theory</a></p></li>
</ul>
<h3 id="problems">problems</h3>
<p>let me state the main problems</p>
<ul>
<li>you do not know how to define a higher inductive type, and now as axioms, it is only propositional equal
<ul>
<li>define the accepted form</li>
<li>define the elem and intro</li>
</ul></li>
<li>there are computation lacking in univalence
<ul>
<li>and inductor for hit</li>
</ul></li>
<li><p>finally i can get an feeling about 0-type, if you have two para path, then they must be joined by an surface, if you have two surface, then they must be joint by a 3-dim ball…. then you will have a very strong point, but it is nontheless a point!!!</p></li>
<li><p>it seems to me that type theory has some mixed things together. i do not know if this is really good, they are like packaged delivery…</p></li>
<li><p>it is really some kind of miracle that it turns out two entirely different things turns out to be the same. h-types etc..</p></li>
<li><p>on the <strong>effitiviness</strong> of type theory and category theory in mathematics…</p></li>
</ul>
<h3 id="ias-notes">IAS notes</h3>
<ul>
<li>definitional eq is just compute to same value… by Martif</li>
</ul>
<h3 id="ref-cmu-course-notes"><a href="#cross-ref-cmu-course">ref-cmu-course</a> notes</h3>
<p>the course has different way telling HTT, it first use IPL, the <em>type theory without variables</em> and corresponding Hayting algebra, then go IPL with type, then ITT… i think this is wired</p>
<ul>
<li>notes of week 1-3 is not about type theory but ITT</li>
<li>week 4
<ul>
<li>judgments</li>
<li>…</li>
</ul></li>
<li><p>in ITT, <span class="math">\(refl\)</span> is the only intro rule!!!!… so it is so boring….</p></li>
<li><p>think <span class="math">\(Id\)</span> as inductively generated family indexed by <span class="math">\(x\)</span> and <span class="math">\(y\)</span></p></li>
<li>in ITT… he saids the <span class="math">\(Id-elem\)</span> is because we only have one <span class="math">\(Id-intro\)</span> so the whole big formula is just… shitty…
<ul>
<li>we will introduce new form of <span class="math">\(Id\)</span> but the shittly rule will continue to be valid… how?</li>
</ul></li>
<li><p>what i am thinking is that, the computation rule of identity is just that applying <span class="math">\(trans(p_1, p_2)\)</span> will not compute because the inductor <span class="math">\(J\)</span> only compute when <span class="math">\(J(a, a, refl_a)\)</span> so we can see that <span class="math">\(refl_x = relf_x^{-1}\)</span> by definition, or say, by computing the inductive, but we are not going to compute for different <span class="math">\(p_1 \neq \p_2\)</span> it is just like <span class="math">\(succ(x)\)</span> will not compute, but can we get something out? like in <span class="math">\(\Pi\)</span>?</p></li>
<li><p>fibers</p></li>
<li><p>by computation, we means that all elements of a type has normal representation. so lem is not computation</p></li>
<li><p>what kind of madness will a guy abstract out something called <span class="math">\(J\)</span> to replace the old-good reflective and transitive? but it is just that all these rules like product etc. is meaningless, the meaning is given by us</p></li>
<li><p>so why it is called induction? you proof the <strong>base case</strong> then you have it for all? it is like no matter how many path you define, the only base case you have is <span class="math">\(refl\)</span>, but why?</p></li>
<li><p>so basically form this, you can deduce the functionality for various types, just use the <span class="math">\(refl\)</span>!… this is silly…</p></li>
<li><strong>lifting property</strong>
<ul>
<li>yes… equal <span class="math">\(x\)</span> gives equal type <span class="math">\(A[x]\)</span>, but what this equal means? for example, if we define a type <span class="math">\(A\)</span> indexed by an interval, then what does two <strong>inductive type</strong> equal means? though it means <span class="math">\(tr(p)\)</span>, but what is it?</li>
<li>he shows that the two type is equal, and also there is a bejection</li>
</ul></li>
<li><p>i think by lecture 08 and the exercises i finally have know what it means in identity type…</p></li>
<li><p>the proof of <span class="math">\(B[a]\)</span> is very related by <span class="math">\(B[a']\)</span>!!! this is what proof-relevant!!!</p></li>
<li><p>inaccessible cardinal, he says that <span class="math">\(\omega\)</span> is an inaccessible cardinal… what a brilliant idea!!!</p></li>
<li><p>h-level: things have large size tends to have large dimension</p></li>
<li><p><span class="math">\(\Pi-F\)</span> is just <span class="math">\(U-I-\Pi\)</span></p></li>
<li>universal polymorphism: i should implement it!!!
<ul>
<li>it is dam difficult to write down the code the universe has no solution…</li>
</ul></li>
<li>axiom of extensionality
<ul>
<li>under context <span class="math">\(x\)</span> <span class="math">\(y\)</span>, you can proof <span class="math">\(x +y = y + x\)</span> and you by transport <span class="math">\(\lambda x. \lambda    y.    x + y = \lambda x. \lambda y.y+x\)</span>, but they are not definitional equal, you can always normalize by applying the function, but how can you normalize a lambda? so we add that if <span class="math">\(Id_A(x, y)\)</span> then <span class="math">\(x\equiv y\)</span></li>
<li>so when you want to know if <span class="math">\(x \equvi y\)</span>, then you have terrible things happening… haha!!! so it is a totally bad idea!!!</li>
<li>actually, with out the extensionality, there is no contradiction in my option…</li>
</ul></li>
<li><p>in mathematics, function is one-side-injection relations, they do not tell at all how the elements is get. but in hott, it is different, set theory use extensionality, but in tt, it is not the case</p></li>
<li><p>if we have extensionality, then because <span class="math">\(x +y\equiv y +x\)</span> then <span class="math">\(\lambda x. \lambda y .x + y \equiv \lambda x. \lambda y. y + x\)</span> then we have the <span class="math">\(refl\)</span></p></li>
<li>he has some remarks about ITT and ETT
<ol style="list-style-type: decimal">
<li>something happened in HoTT is bad</li>
<li>ITT type checking is intractable… why?</li>
</ol></li>
<li><p>so my version is not ETT… it is incomplete ITT…</p></li>
<li><p>so in the past, they use ITT just for the decidable type checking, without even thinking they can add more path…</p></li>
<li><p>why not category - groupoid - set, we can pick anyone… actually??</p></li>
<li><p>in ETT, we have <strong>strict sets</strong> they are just eq, but in ITT we proof that the <span class="math">\(Id\)</span> is equal, but not judgementally, which cannot be done</p></li>
<li><p>in the path thing, we can talk about how a proof can be conveyed to a proof in other place!!</p></li>
<li><p>i think because we have new identity, we have trouble with <span class="math">\(J\)</span></p></li>
<li><p>in ITT, everything is cool, but he do not want to go into meta-theory</p></li>
<li><p>for Harper, if it has no computational meaning, it is basically useless</p></li>
<li><p>yes… the inductive rule of identity, it worried me greatly…</p></li>
<li><p>it is the lie holds only by bigger lies…</p></li>
<li><p>so in hott, functors is more basic than functions!</p></li>
<li><p>homotopy is assembly… and hott is advanced pl…</p></li>
<li><p>compile and encoding nat in sets</p></li>
<li>so it is not safe to say <span class="math">\(=_\mathcal{U}\)</span>, but we say… and make them higher!
<ul>
<li>in ITT they are different, in equivalence, we use homtopoy, not function of types</li>
</ul></li>
<li><p>function extensionality: in the ITT setting, we just do not know, in HoTT, we said there are one path, but we cannot define now. and in ETT, we said they are just equal</p></li>
<li><p>negative of type has easy path structure, but positive type has not….</p></li>
<li><p>i think i begin to have a metal model on what’s going on in this kind of things…</p></li>
<li><p>yes… small type matters in theory</p></li>
<li><p>what is universe? if we can identify universe as a small thing, we might make true progress</p></li>
<li><p>i still cannot understand the book i think</p></li>
</ul>
<h2 id="references">references</h2>
<ul>
<li><span id="cross-ref-hott" class="crosslink">ref-hott</span> <em>Homotopy Type Theory</em></li>
<li><span id="cross-ref-cmu-course" class="crosslink">ref-cmu-course</span> <a href="http://www.cs.cmu.edu/~rwh/courses/hott">http://www.cs.cmu.edu/~rwh/courses/hott</a></li>
<li><span id="cross-ref-ias" class="crosslink">ref-ias</span> <a href="http://uf-ias-2012.wikispaces.com/Higher+Inductive+Types">http://uf-ias-2012.wikispaces.com/Higher+Inductive+Types</a></li>
</ul>
<h1 id="category">category</h1>
<h2 id="idea-1">idea</h2>
<p>it is a very good language we use to study the structure</p>
<p>there are things called higher categories, but i think i cannot study them now…</p>
<h2 id="category-1">category</h2>
<h3 id="category-2">category</h3>
<ul>
<li><span><span id="cross-category-theory"></span><span id="cross-category" class="crosslink">category</span></span>
<ul>
<li><span id="cross-object" class="crosslink">object</span></li>
<li><span id="cross-morphism" class="crosslink">morphism</span>
<ul>
<li><span id="cross-domain" class="crosslink">domain</span></li>
<li><span id="cross-codomain" class="crosslink">codomain</span></li>
<li><span id="cross-identity-morphism" class="crosslink">identity morphism</span>: <span class="math">\(\forall f: A\to B: {\text{id}}_B \circ f = f \circ {\text{id}}_A\)</span>
<ul>
<li>identity, it is not <a href="#cross-identity-type">identity type</a>, it should be <a href="#cross-refl">refl</a>, isomorphism is <a href="#cross-identity-type">identity type</a></li>
<li><span id="cross-left-inverse" class="crosslink">left inverse</span>, <span id="cross-right-inverse" class="crosslink">right inverse</span>, <span id="cross-inverse" class="crosslink">inverse</span></li>
<li>unique: if one, must be it, if two, <span class="math">\(a= ab = b\)</span></li>
<li><span class="math">\(ff = f\)</span> is not sufficient: constant map, algebraic inverse</li>
</ul></li>
<li><span id="cross-isomorphism" class="crosslink">isomorphism</span>: two <a href="#cross-morphism">morphism</a> such that diagram <code>id_A A f/g B id_B</code> commute</li>
<li><span id="cross-monomorphism" class="crosslink">monomorphism</span>: <span class="math">\(f g = f h\)</span> implies <span class="math">\(g = h\)</span>
<ul>
<li>if <span class="math">\(f: A\to B\)</span> has a <a href="#cross-left-inverse">left inverse</a> <span class="math">\(g: B\to A\)</span>, <span class="math">\(g f = id_A\)</span>, then <span class="math">\(f\)</span> is monomorphism, and <span class="math">\(g\)</span> is <a href="#cross-epimorphism">epimorphism</a>. it shows that the idea of left/right inverse is useful sometimes</li>
</ul></li>
<li><span id="cross-epimorphism" class="crosslink">epimorphism</span></li>
</ul></li>
<li><a href="#cross-associative">associative</a> . <a href="#cross-composition-law">composition law</a> of <a href="#cross-morphism">morphism</a></li>
<li>exists <a href="#cross-identity-morphism">identity morphism</a></li>
<li>it is said that <a href="#cross-category-theory">category theory</a> is the partial algebra of arrows, so all definition should be using arrows</li>
</ul></li>
</ul>
<h3 id="category-category">category category</h3>
<ul>
<li><a href="#cross-category">category</a> of <a href="#cross-category">category</a>, <span class="math">\({\mathcal{Cat}}\)</span> (or all small categories)
<ul>
<li><a href="#cross-object">object</a>: <a href="#cross-category">category</a></li>
<li><a href="#cross-morphism">morphism</a>: <span id="cross-functor" class="crosslink">functor</span>, preserve <a href="#cross-identity-morphism">identity morphism</a> and <a href="#cross-law-of-composition">law of composition</a>: <span class="math">\(F({\text{id}}_x) = {\text{id}}_{F(x)}\)</span>, <span class="math">\(F(g\circ f) = F(g) \circ F(f)\)</span>
<ul>
<li><a href="#cross-identity-morphism">identity morphism</a>: <span id="cross-identity-functor" class="crosslink">identity functor</span></li>
<li>it preserve all commuting diagrams
<ul>
<li>this is not sufficient, consider a functor maps to a constant and a constant map</li>
</ul></li>
</ul></li>
<li><a href="#cross-law-of-composition">law of composition</a>: <a href="#cross-function-composition">function composition</a></li>
<li><span id="cross-equivalence-of-category" class="crosslink">equivalence of category</span>: <a href="http://en.wikipedia.org/wiki/Equivalence_of_categories">Wikipedia</a>. it is two map in <span class="math">\({\mathcal{Cat}}\)</span> such that …</li>
</ul></li>
</ul>
<h3 id="functor-category">functor category</h3>
<ul>
<li><a href="#cross-category">category</a> of <a href="#cross-functor">functor</a>s <span class="math">\({\mathcal{D}}\to{\mathcal{C}}= {\mathcal{C}}^{\mathcal{D}}\)</span>
<ul>
<li><a href="#cross-object">object</a>: <a href="#cross-functor">functor</a></li>
<li><a href="#cross-morphism">morphism</a>: <span id="cross-natural-transform" class="crosslink">natural transform</span>, for <span class="math">\(T,U:{\mathcal{D}}\to{\mathcal{C}}\)</span>, <span class="math">\(\tau: {\mathcal{D}}\to (T\downarrow U)\)</span> such that <span class="math">\(P\circ \tau = Q\circ \tau = {\text{Id}}_{\mathcal{D}}\)</span>
<ul>
<li><a href="#cross-isomorphism">isomorphism</a>: <span id="cross-natural-isomorphism" class="crosslink">natural isomorphism</span>
<ul>
<li>if <span class="math">\(\alpha_A\)</span> is <a href="#cross-isomorphism">isomorphism</a>s, then we have natural isomorphism</li>
</ul></li>
</ul></li>
<li><a href="#cross-law-of-composition">law of composition</a>. you can see it</li>
</ul></li>
</ul>
<h3 id="comma-category">comma category</h3>
<ul>
<li><span id="cross-comma-category" class="crosslink">comma category</span>: <span class="math">\((x\downarrow \mathcal{U})\)</span>, image two category with functors, left one with special element <span class="math">\(A\)</span>, objects is <span class="math">\((D, h)\)</span> like correlated line and point, and morphism as morphism in <span class="math">\({\mathcal{D}}\)</span>
<ul>
<li>general form: <a href="http://en.wikipedia.org/wiki/Comma_category">Wikipedia</a></li>
<li>it is not like <a href="#cross-coslice-category">coslice category</a>!</li>
</ul></li>
<li><span id="cross-universal-arrow" class="crosslink">universal arrow</span>: <a href="#cross-initial">initial</a> in <a href="#cross-comma-category">comma category</a>
<ul>
<li>if every element has an universal arrow, then we can define a reverse functor
<ul>
<li>see <a href="#cross-ref-category-notes">ref-category-notes</a> for diagram <code>f| A/B =u_A/u_B= UFA/ UFB | UFf</code></li>
<li>check preserve id: ok + unique = defined</li>
<li>check preserve law: think by “moving equal path on graph”</li>
<li>and the arrows is an <a href="#cross-natural-transform">natural transform</a> from <span class="math">\({\text{Id}}_{\mathcal{C}}\)</span> to <span class="math">\(F\)</span></li>
<li>though we do not know if the <a href="#cross-initial">initial</a> is unique, we can still define it</li>
</ul></li>
<li>example: <a href="#cross-forgetful-functor">forgetful functor</a> from <a href="#cross-monoid">monoid</a> <span class="math">\(\mathcal{Mon}\)</span> to <span class="math">\(\mathcal{Set}\)</span>, every set has a universal arrow, by freely generate words in the monoid</li>
</ul></li>
<li><span id="cross-diagram" class="crosslink">diagram</span>
<ul>
<li>a <span class="math">\(\mathcal{D}\)</span>-shaped diagram in <span class="math">\(\mathcal{C}\)</span> is a functor <span class="math">\(F: \mathcal{D}\to \mathcal{C}\)</span></li>
<li><span class="math">\(\mathcal{D}[\mathcal{C}]\)</span> is the category of diagrams</li>
</ul></li>
<li><span id="cross-diagonal-functor" class="crosslink">diagonal functor</span>, <span class="math">\(\Delta:{\mathcal{C}}\to {\mathcal{C}}^{\mathcal{D}}\)</span>
<ul>
<li><a href="#cross-object">object</a>: to constant <a href="#cross-diagram">diagram</a> <span class="math">\({\mathcal{D}}\to{\mathcal{C}}\)</span></li>
<li><a href="#cross-morphism">morphism</a>: <a href="#cross-natural-transform">natural transform</a> of them</li>
</ul></li>
</ul>
<h3 id="colimit-and-limit">colimit and limit</h3>
<ul>
<li><span id="cross-colimit" class="crosslink">colimit</span>: for functor <span class="math">\(J:{\mathcal{D}}\to{\mathcal{C}}\)</span> <a href="#cross-universal-arrow">universal arrow</a> from <span class="math">\(J\)</span> to <a href="#cross-diagonal-functor">diagonal functor</a> <span class="math">\(\Delta:{\mathcal{C}}\to{\mathcal{C}}^{\mathcal{D}}\)</span> <code>fix me</code>. mapping out
<ul>
<li><span id="cross-initial" class="crosslink">initial</span></li>
<li><span id="cross-coproduct" class="crosslink">coproduct</span>
<ul>
<li><span id="cross-generalized-coproduct" class="crosslink">generalized coproduct</span></li>
</ul></li>
<li><span id="cross-coequalizer" class="crosslink">coequalizer</span></li>
<li><span id="cross-pushout" class="crosslink">pushout</span></li>
<li><span id="cross-cocomplete" class="crosslink">cocomplete</span>
<ul>
<li>have all <a href="#cross-colimit">colimit</a>s</li>
<li><a href="#cross-generalized-coproduct">generalized coproduct</a> and <a href="#cross-coequalizer">coequalizer</a> is sufficient <code>fix me</code>
<ul>
<li>proof for <span class="math">\(\mathcal{Set}\)</span> and <span class="math">\(\mathcal{Mon}\)</span> <code>fix me</code></li>
</ul></li>
</ul></li>
</ul></li>
<li><span id="cross-limit" class="crosslink">limit</span>: mapping in
<ul>
<li><span id="cross-terminal" class="crosslink">terminal</span></li>
<li><span id="cross-product" class="crosslink">product</span></li>
<li><span id="cross-pullback" class="crosslink">pullback</span></li>
<li><span id="cross-equalizer" class="crosslink">equalizer</span></li>
<li><span id="cross-complete" class="crosslink">complete</span>
<ul>
<li>have all <a href="#cross-limit">limit</a>s</li>
<li><a href="#cross-product">product</a> and <a href="#cross-equalizer">equalizer</a> is sufficient</li>
</ul></li>
</ul></li>
<li><span id="cross-adjoint-functor" class="crosslink">adjoint functor</span>
<ul>
<li>dual</li>
<li>in Wikipedia, it says that it means optimization</li>
<li><span class="math">\(\mathcal{Ab}(F(S), A) \approxeq \mathcal{S}(S, U(A))\)</span> between the functor take <span id="cross-set" class="crosslink">set</span> to <span id="cross-freely-generated-abelian-group" class="crosslink">freely generated abelian group</span> and the functor that from the group to the set. it means the the morphisms in one category can be fully described by morphisms in another a map from <span class="math">\(S\)</span> to <span class="math">\(U(A)\)</span> fully describe the homomorphisms from <span class="math">\(F(S)\)</span> to <span class="math">\(A\)</span> ## example</li>
</ul></li>
<li><p><span class="math">\(Id_\mathcal{G}\)</span> the ideal functor of <span id="cross-group" class="crosslink">group</span>, and <span class="math">\(^op\)</span> the opposite functor has a natural isomorphism</p></li>
<li><p><span id="cross-category-connected" class="crosslink">category connected</span></p></li>
<li>constructs on category
<ul>
<li><span id="cross-product-category" class="crosslink">product category</span></li>
<li><span id="cross-dual-category" class="crosslink">dual category</span></li>
<li><span id="cross-skeleton-category" class="crosslink">skeleton category</span>
<ul>
<li><a href="#cross-category-equivalence">category equivalence</a> <code>fix me: ce, and this</code>
<ul>
<li>injection <span id="cross-functor" class="crosslink">functor</span>: <span class="math">\(J: sk\mathcal{l}\to \mathcal{l}\)</span></li>
<li>inverse functor: you know~</li>
</ul></li>
</ul></li>
<li><span id="cross-arrow-category" class="crosslink">arrow category</span></li>
<li><span id="cross-slice-category" class="crosslink">slice category</span></li>
<li><span id="cross-coslice-category" class="crosslink">coslice category</span>
<ul>
<li><span class="math">\(x\backslash \mathcal{C}\)</span> is the category <span class="math">\(f: x\to y\)</span> as <span id="cross-object" class="crosslink">object</span>s, and <span class="math">\(\lambda:f\to g\)</span> such that <span class="math">\(\lambda \circ f = g\)</span> as <span id="cross-morphism" class="crosslink">morphism</span>s</li>
<li>when the category is a groupoid, then <span class="math">\(\lambda = g \circ f^{-1}\)</span> is determined</li>
</ul></li>
</ul></li>
</ul>
<h2 id="higher-category">higher category</h2>
<h2 id="references-1">references</h2>
<ul>
<li><span id="cross-ref-youtube-category-video" class="crosslink">ref-youtube-category-video</span> <a href="http://simonwillerton.staff.shef.ac.uk/TheCatsters">http://simonwillerton.staff.shef.ac.uk/TheCatsters</a>
<ul>
<li>i understand <a href="#cross-limit">limit</a> from here</li>
</ul></li>
<li><span id="cross-ref-category-awodey" class="crosslink">ref-category-awodey</span> <em>Category Theory</em>, Awodey
<ul>
<li>my intro book</li>
</ul></li>
<li><span id="cross-ref-category-notes" class="crosslink">ref-category-notes</span> <em>Category Theory Lecture Notes</em>
<ul>
<li>excellent! this will be great for review, but i do not know if one can read this first</li>
</ul></li>
</ul>
<h1 id="set">set</h1>
<h2 id="idea-2">idea</h2>
<p>types that has no non-trivial <span id="cross-identity" class="crosslink">identity</span>, 0-type</p>
<ul>
<li><span class="math">\(\mathcal{Set}\)</span>
<ul>
<li>morphism: <span id="cross-function" class="crosslink">function</span></li>
<li>iso: <span id="cross-bijection" class="crosslink">bijection</span></li>
<li>mono: <span id="cross-injection" class="crosslink">injection</span></li>
<li>epi: <span id="cross-surjection" class="crosslink">surjection</span></li>
<li>product:</li>
<li>coproduct:</li>
</ul></li>
<li><p><span id="cross-pointed-set" class="crosslink">pointed set</span> <span class="math">\(\mathcal{Set}_*\)</span></p></li>
<li><p><span id="cross-subset" class="crosslink">subset</span></p></li>
<li><p><span id="cross-cover" class="crosslink">cover</span></p></li>
<li><span id="cross-cardinal" class="crosslink">cardinal</span></li>
<li><p><span id="cross-ordinal" class="crosslink">ordinal</span></p></li>
</ul>
<hr />
<p>old notes on set theory</p>
<pre><code># notes on set theory

## first-order logic

## set

* axioms
    * extensionality
    * pairing
    * union
    * power
    * function
        * injective
        * surjective
        * bijective
    * replacement
    * infinity &amp; empty
* set seq limit
    * `lim inf A_i = \/_i /\_{j &gt;=i} A_j`, in all but finite
    * `lim sup A_i = /\_i \/_{j &gt;=i} A_j`, in infinite sets
    * `lim A_i`
## ordinal numbers

*we count set naturally, and compare the size*

* partial ordering
    * `p !&lt; p`
    * `p &lt; q &amp;&amp; q &lt; r =&gt; p &lt; r`
    * `(P, &lt;)` is a pos, `X` a subset
        * maximal of `X`: `forall x a !&lt; x`
        * minimal..: `forall x x !&lt; a`
        * greatest..: `forall x x&lt;= a` =&gt; max
        * least..: `forall x a&lt;= x` =&gt; min **do it!**
        * upper bound: `forall x, x &lt;= a`
        * lower bound: `forall x, a &lt;= x`
        * sup: least upper bound
        * inf: greatest lower bound
    * order-perserving, isomorphism, automorphism (in order)
* linear ordering
    * `forall p,q: p &lt; q || p == q || q &lt; p`
    * increasing, des, strict..?
* well ordering: linear ordering that every non-empty subset has least
    * initial segment
* theorems
    * increasing function of wo `f(x) &gt;= x`
    * only automorphism of wo is `i_P`
    * if two wo isomorphic, it is unique
    * for two wo, either they are iso, or one is other's initial segment
* ordinal numbers
    * 1, 2, 3, 4, .... omega

**fix me**


## cardinal numbers

* what it means by: `|X| = |Y|` and `|X| &lt; |Y|`
* `|X| &lt; |P(X)|`
* `|A| &lt;= |B| &amp;&amp; |B| &lt;= |A| =&gt; |A| = |B|`
* cardinal arith
* `|P(A)| = 2^|A|`
* cardinal number: `forall b &lt; a: |a| != |b|`
* wo `W`: `|W|` = least ordinal `a`: `|W| = |a|`
* alephs: infinite cardinals = limit ordinals
    * `aleph_0 = omega`
    * `aleph_alpha + aleph_beta = aleph_alpha * aleph_beta = max(aleph_alpha, aleph_beta)`
    * **fix me**

## real numbers

* `|R| = 2^{aleph_0}`
* continuum hypothesis: `2^{aleph_0} = aleph_1}`
* **fix me**

## ac

* ac: for a family of set, exists choice function
    * every set can be well-ordered
    * Zorn's lemma: every linear subset has upper bound =&gt; hax maximal element

</code></pre>
<h1 id="topological-space">topological space</h1>
<h2 id="idea-3">idea</h2>
<p>it describe what we means by a space, which has a notation of <strong>nearness</strong> of points, which means the point have some <strong>extension</strong>, so infinite extension will destroy it</p>
<h2 id="definition-1">definition</h2>
<ul>
<li><span><span id="cross-topology"></span><span id="cross-topological-space" class="crosslink">topological space </span></span>
<ul>
<li>set, <span class="math">\(A\)</span></li>
<li>open sets <span class="math">\(\mathcal{T}\)</span></li>
<li><span class="math">\(\{A, \emptyset\} \subset \mathcal{T}\)</span></li>
<li><span class="math">\(\mathcal{T}\)</span> closed under finite intersection and any union</li>
</ul></li>
<li><span class="math">\(\mathcal{U}\)</span>
<ul>
<li>morphism: <span id="cross-continuous-function" class="crosslink">continuous function</span></li>
<li><span id="cross-path" class="crosslink">path</span>
<ul>
<li><span id="cross-loop" class="crosslink">loop</span></li>
</ul></li>
<li>mono and epi is reduced from set</li>
<li>isomorphism: <span id="cross-homeomorphism" class="crosslink">homeomorphism</span> is not reduced from set!</li>
<li>product: product set with weak topology for projection</li>
<li>coproduct:</li>
</ul></li>
<li><span id="cross-pointed-space" class="crosslink">pointed space</span>
<ul>
<li><span id="cross-morphism" class="crosslink">morphism</span>: <span id="cross-continuous" class="crosslink">continuous</span> map closed by basepoint</li>
</ul></li>
<li>path
<ul>
<li><span id="cross-continuous-function" class="crosslink">continuous function</span> from <span id="cross-interval" class="crosslink">interval</span> to <span id="cross-space" class="crosslink">space</span></li>
<li><span class="math">\(c_x\)</span> constant loop</li>
<li><span class="math">\(f\cdot g\)</span> the path that…</li>
<li><span class="math">\(f^{-1}\)</span> the path that…</li>
<li>it is not <span id="cross-groupid" class="crosslink">groupid</span>, because the inverse is not <span id="cross-groupid-inverse" class="crosslink">groupid inverse</span>, but that’s true in <span id="cross-homotopy-space" class="crosslink">homotopy space</span></li>
</ul></li>
</ul>
<h3 id="connectedness">connectedness</h3>
<ul>
<li><span id="cross-connected-space" class="crosslink">connected space</span></li>
<li><span id="cross-path-connected-space" class="crosslink">path connected space</span></li>
<li><span id="cross-arc-connected-space" class="crosslink">arc connected space</span></li>
<li><span id="cross-locally-path-connected" class="crosslink">locally path connected</span>
<ul>
<li>locally path connected + <span id="cross-connected" class="crosslink">connected</span> <span class="math">\(\Rightarrow\)</span> <span id="cross-path-connected" class="crosslink">path connected</span></li>
<li>a example of path connected but not locally path connected <a href="http://math.stackexchange.com/questions/135463/path-connectedness-and-locally-path-connected">http://math.stackexchange.com/questions/135463/path-connectedness-and-locally-path-connected</a></li>
</ul></li>
</ul>
<h2 id="references-2">references</h2>
<h1 id="homotopy-space">homotopy space</h1>
<h2 id="example">example</h2>
<ul>
<li>real projective space
<ul>
<li>the real projective space <span class="math">\(\mathbb{R}P^n\)</span> is obtained by gluing antipodal points of <span class="math">\(S^n\)</span></li>
</ul></li>
</ul>
<h2 id="idea-4">idea</h2>
<ul>
<li>the subject of algebraic topology is to give <span id="cross-algebra" class="crosslink">algebra</span> structure on a <span id="cross-space" class="crosslink">space</span></li>
</ul>
<h2 id="homotopy">homotopy</h2>
<h3 id="idea-5">idea</h3>
<p>homotopy in <span id="cross-category" class="crosslink">category</span>?</p>
<p>two <span id="cross-continuous-function" class="crosslink">continuous function</span> between <span id="cross-space" class="crosslink">space</span> <span class="math">\(f, g: X\to Y\)</span> is homotopy if they can be <strong>continuously deformed</strong></p>
<p>see <span id="cross-homotopy-space" class="crosslink">homotopy space</span></p>
<h3 id="definition-2">definition</h3>
<p><span id="cross-continuous" class="crosslink">continuous</span> function from <span class="math">\(h: X\times I\to Y\)</span>, with <span class="math">\(h(x, 0) = f(x)\)</span>, <span class="math">\(h(x, 1) = g(x)\)</span></p>
<h3 id="question">question</h3>
<ul>
<li>why <span id="cross-real-line" class="crosslink">real line</span> is used here? it means the space is inherently real?</li>
<li>can we change to other space?</li>
</ul>
<h2 id="homotopy-space-1">homotopy space</h2>
<ul>
<li>there is a <span id="cross-functor" class="crosslink">functor</span> from <span id="cross-space" class="crosslink">space</span> to the homotopy spaces <span class="math">\(h\mathcal{U}\)</span></li>
<li>object: same, just <span id="cross-space" class="crosslink">space</span></li>
<li><span id="cross-morphism" class="crosslink">morphism</span>: <span id="cross-continuous-function" class="crosslink">continuous function</span> to the <span id="cross-homotopy" class="crosslink">homotopy</span> class</li>
<li><p>the <span id="cross-isomorphism" class="crosslink">isomorphism</span>s is <span class="math">\(f \cdot g \simeq id\)</span> things, which is called <span id="cross-homotopy-equivalence" class="crosslink">homotopy equivalence</span> in <span class="math">\(\mathcal{U}\)</span></p></li>
<li><p><span id="cross-fundamental-groupoid" class="crosslink">fundamental groupoid</span></p></li>
<li><span id="cross-pointed-homotopy-space" class="crosslink">pointed homotopy space</span></li>
<li><p><span id="cross-fundamental-group" class="crosslink">fundamental group</span></p></li>
</ul>
<h2 id="pointed-homotopy-space">pointed homotopy space</h2>
<h3 id="idea-6">idea</h3>
<p>just like <span id="cross-homotopy-space" class="crosslink">homotopy space</span>, <span class="math">\(h\mathcal{T}\)</span></p>
<h3 id="functor">functor</h3>
<ul>
<li><span id="cross-object" class="crosslink">object</span>: same, just <span id="cross-pointed-space" class="crosslink">pointed space</span></li>
<li><span id="cross-morphism" class="crosslink">morphism</span>: point-closed <span id="cross-continuous-function" class="crosslink">continuous function</span> to homotopy classes under homotopy from <span class="math">\((X,x)\)</span> to <span class="math">\((Y,y)\)</span>, the homotopy keeps basepoint fixed all the time, isomorphism is also called based homotopy equivalence</li>
<li>the fundamental group functor factor though pointed homotopy space, because for a 2 based homotopy equivalence map, they maps to same group</li>
<li><p>an based homotopy equivalence induce an isomorphism in fundamental group</p></li>
<li><p>is there exist two continuous function that can only be homotopy in <span class="math">\(h\mathcal{U}\)</span> but not <span class="math">\(h\mathcal{T}\)</span>, i.e. only exist homotopy that moves basepoint in the middle of the transform <code>fix me</code></p></li>
</ul>
<h2 id="homotopy-invariance">homotopy invariance</h2>
<ul>
<li><span class="math">\(h: p\simeq q\)</span> then we have paths <span class="math">\(a(t): p(x)\to q(x)\)</span> in <span class="math">\(Y\)</span> by <span class="math">\(a(t) = h(x, t)\)</span> which is the homotopy reduced to <span class="math">\(Y\)</span> by projection on base point <span class="math">\(x\)</span></li>
<li><p>then we have <span class="math">\[\gamma[a]\circ p_* = q_*: \pi_1(X, x)\dashrightarrow \pi_1(Y, p(x)) \to \pi_1(Y, q(x))\]</span></p></li>
<li><p>proof by proofing that a certain path is zero, which we can construct as a border of a map from <span class="math">\(I\times I\)</span> which is contractible, so we proof it is homotopy to zero</p></li>
<li><p>this proofs, if you map by homotopy, then the group is isomorphism by some path isomorphism</p></li>
<li>relation to <span id="cross-fundamental-group" class="crosslink">fundamental group</span></li>
<li><p>because <span class="math">\(\mathcal{U}\to h\mathcal{U}\)</span> has no base point, we cannot get the fundamental group, but we have <span class="math">\(f: X\to Y\)</span> is homotopy equivalence, then <span class="math">\(f_*\)</span> is isomorphism for all <span class="math">\(x\)</span>, the proof uses the homotopy function induce isomorphism in fundamental group, blabala…</p></li>
<li>a space is contractible if there is an isomorphism in homotopy space to zero</li>
<li>then the fundamental group is zero, because there fundamental group is isomorphic</li>
<li><p>but this is not necessory, for example, there are no isomorphism form <span class="math">\(S^2\)</span> to <span class="math">\(D^0\)</span> but we the fundamental group is still zero, this is because higher homotopy strucutrue</p></li>
</ul>
<h2 id="fundamental-groupoid">fundamental groupoid</h2>
<h3 id="idea-7">idea</h3>
<p>functor from space <span class="math">\(\mathcal{U}\)</span> to <span id="cross-groupoid" class="crosslink">groupoid</span> <span class="math">\(\mathcal{GP}\)</span></p>
<ul>
<li><span class="math">\([f]\)</span> the <span id="cross-homotopy" class="crosslink">homotopy</span> class of <span id="cross-path" class="crosslink">path</span> <span class="math">\(f\)</span> in the <strong>paths</strong> from <span class="math">\(x\)</span> to <span class="math">\(y\)</span>, it is not just <span id="cross-homotopy" class="crosslink">homotopy</span> of the path considered as <span class="math">\(I \to X\)</span>, in a type theory view, this might be easy, for we can consider it be the type <span class="math">\(Path(X, x, y)\)</span></li>
<li><span class="math">\(f: x \to y\)</span>, <span class="math">\(g: y\to z\)</span></li>
<li><span class="math">\([g][f] = [g\cdot f]\)</span>, notice the order</li>
<li><span class="math">\([f]^{-1} = [f^{-1}]\)</span></li>
<li>it is a <span id="cross-groupiod" class="crosslink">groupiod</span>
<ul>
<li><span class="math">\([f]^{-1}[f] = [f^{-1}f] = [c_x]\)</span></li>
</ul></li>
</ul>
<p>by <span id="cross-van-Kampen" class="crosslink">van Kampen</span>, fundamental groupoid preserve certain <span id="cross-colimit" class="crosslink">colimit</span>s</p>
<h3 id="relation">relation</h3>
<p>for a <span id="cross-path-connected-space" class="crosslink">path connected space</span>, the fundamental groupoid is <span id="cross-groupoid-connected" class="crosslink">groupoid connected</span>, which is a special case of <span id="cross-category-connected" class="crosslink">category connected</span>, so it is <span id="cross-category-equivalence" class="crosslink">category equivalence</span> to the <span id="cross-skeleton-category" class="crosslink">skeleton category</span> of fundamental groupoid, which is <span id="cross-fundamental-group" class="crosslink">fundamental group</span></p>
<h2 id="van-kampen-theorem">van Kampen theorem</h2>
<h3 id="idea-8">idea</h3>
<p>that the fundamental groupoid functor preserves certain colimits</p>
<h3 id="groupoid-version">groupoid version</h3>
<ul>
<li><span class="math">\(\mathcal{O}\)</span> be a <span id="cross-cover" class="crosslink">cover</span> of <span id="cross-space" class="crosslink">space</span> <span class="math">\(X\)</span> by <span id="cross-path-connected" class="crosslink">path connected</span> <span id="cross-open" class="crosslink">open</span> sets, closed under finite <span id="cross-intersection" class="crosslink">intersection</span></li>
<li>as a category morphism are <span id="cross-inclusion" class="crosslink">inclusion</span>s of subsets, gives a <span id="cross-diagram" class="crosslink">diagram</span> <span class="math">\[\Pi | \mathcal{O}: \mathcal{O}\to\mathcal{GP}\]</span></li>
<li>the <span id="cross-groupoid" class="crosslink">groupoid</span> <span class="math">\(\Pi(X)\)</span> is the <span id="cross-colimit" class="crosslink">colimit</span> of the diagram <span class="math">\[\Pi(X)\cong colim_{U\in \mathcal{O}}\Pi(U)\]</span></li>
</ul>
<p>the proof is very natural</p>
<h3 id="group-version">group version</h3>
<p>statement same as above</p>
<ul>
<li>first by skeleton category, we proof for finite case, it is because we need a base to inductively define the reverse <span class="math">\(J\)</span> for skeleton category</li>
<li>then it is proofed for infinite verson <code>fix me</code></li>
</ul>
<h3 id="example-1">example</h3>
<p>p20 proposition and exercises bellow, i do not know how to compute the push outs… <code>fix me: not understand the pushout now</code></p>
<h2 id="fundamental-group">fundamental group</h2>
<ul>
<li>table of contents {: toc}</li>
</ul>
<h3 id="idea-9">idea</h3>
<ul>
<li><p><span id="cross-functor" class="crosslink">functor</span> from <span id="cross-pointed-space" class="crosslink">pointed space</span> <span class="math">\(\mathcal{T}\)</span> to <span id="cross-group" class="crosslink">group</span> <span class="math">\(\mathcal{G}\)</span></p></li>
<li>functor</li>
<li>object: point space to group</li>
<li>morphism: <span class="math">\(p: X\to Y\)</span> to group <span class="math">\(homomorphism\)</span>, <span class="math">\(p_*: \pi_1(X, x)\to \pi_1(Y, y)\)</span> by <span class="math">\(p_*[f] = [p\circ f]\)</span></li>
<li>certain colimit is preserved under fundamental group <span id="cross-van-Kampen" class="crosslink">van Kampen</span></li>
<li><p><span id="cross-product" class="crosslink">product</span> is preserved, it is proofed by <strong>universal property</strong> but <code>fix me</code></p></li>
<li><p>we see that <span class="math">\(\pi_1(X,x)\)</span> the homotopy <span id="cross-loop" class="crosslink">loop</span>s on <span class="math">\(x\)</span> is a <span id="cross-group" class="crosslink">group</span></p></li>
</ul>
<h3 id="dependency-on-base-point">dependency on base point</h3>
<ul>
<li><span class="math">\(a\)</span> a path, <span class="math">\(\gamma[a]\)</span> the homomorphism to move point</li>
<li><span class="math">\(\gamma[a][f] = [a\cdot f \cdot a^{-1}]\)</span></li>
<li>it only depends on the <span id="cross-homotopy" class="crosslink">homotopy</span> class of <span class="math">\(a\)</span></li>
<li>it is <span id="cross-isomorphism" class="crosslink">isomorphism</span> with inverse <span class="math">\(\gamma[a^{-1}]\)</span></li>
<li>if the group is <span id="cross-abelian" class="crosslink">abelian</span> we have <span class="math">\(\gamma[b][f] = \gamma[a][f]\)</span>, you should view the structure in the groupoid, and switch basepoint</li>
<li>so there are <span class="math">\(n\)</span> kinds of path induced isomorphism between <span class="math">\(\pi_1(X,x)\)</span> and <span class="math">\(\pi_1(X, y)\)</span> where <span class="math">\(n\)</span> is the number of homotopy class of the path between the two point, so one homotopy class means one isomorphism is path induced, and then we can use this way to identity two group</li>
<li><span class="math">\(S^1\times S^1\)</span> is abelian, the path induced homomorphism</li>
<li>this is not the case when <span class="math">\(x=y\)</span>, because it might cancel by <span class="math">\(f\)</span>, for example the isomorphism of <span class="math">\(\mathbb{Z}\)</span> is never induced by path. so there should be two non-homotopy maps from <span class="math">\(S^1\)</span> to <span class="math">\(S^1\)</span></li>
</ul>
<h3 id="example-2">example</h3>
<p>i think there are many homotopy class on <span class="math">\(S^1 \times S^1\to S^1\times S^1\)</span>, examples are projection, id, and swap</p>
<h2 id="calculation">calculation</h2>
<ul>
<li><p><span class="math">\(\pi_1(\mathbb{R}) = 0\)</span></p></li>
<li><span class="math">\(\pi_1(S^1) = \mathbb{Z}\)</span></li>
<li>define a homomorphism <span class="math">\([f]:I\to \pi(S^1,1)\)</span></li>
<li><p><code>fix me</code></p></li>
</ul>
<h3 id="exercises">exercises</h3>
<p>from <em><span id="cross-A-Concise-Course-in-Algebraic-Topology" class="crosslink">A Concise Course in Algebraic Topology</span></em></p>
<ol style="list-style-type: decimal">
<li>The Brouwer fixed point theorem</li>
<li>The fundamental theorem of algebra</li>
<li>exercises <code>fix me</code>, i do not know what’s the <span class="math">\(deg\)</span> and what’s topological group</li>
<li>for <span id="cross-real-projective-space" class="crosslink">real projective space</span> <code>fix me</code></li>
</ol>
<h3 id="relations">relations</h3>
<p><span id="cross-homotopy-space" class="crosslink">homotopy space</span> and <span id="cross-pointed-homotopy-space" class="crosslink">pointed homotopy space</span></p>
<ul>
<li>factor though <span class="math">\(h\mathcal{T}\to \mathcal{G}\)</span> <code>fix me</code></li>
<li>this is obvious, if two continuous map is same in <span class="math">\(h\mathcal{T}\)</span>, then they have a <span id="cross-homotopy" class="crosslink">homotopy</span> fix basepoint, which means <span class="math">\(a(t)\)</span> above is constant, which means they maps to same fundamental group</li>
<li>if <span class="math">\(f:X \to Y\)</span> is iso in <span id="cross-homotopy-space" class="crosslink">homotopy space</span> then <span class="math">\(f_*: \pi_1(X, x) \to \pi_1(Y, f(x))\)</span> is <span id="cross-isomorphism" class="crosslink">isomorphism</span> for all <span class="math">\(x\)</span>, it is not a functor</li>
<li><p>for <span id="cross-contractible" class="crosslink">contractible</span> space, the fundamental group is 0</p></li>
<li><p><span id="cross-simply-connected" class="crosslink">simply connected</span> fundamental group is zero and <span id="cross-path-connected" class="crosslink">path connected</span></p></li>
</ul>
<h2 id="covering-space">covering space</h2>
<h3 id="idea-10">idea</h3>
<ul>
<li><span class="math">\(p: E\to B\)</span></li>
<li><span id="cross-surjective" class="crosslink">surjective</span></li>
<li>each <span class="math">\(b\in B\)</span>, has <span id="cross-open" class="crosslink">open</span> <span id="cross-neighborhood" class="crosslink">neighborhood</span> <span class="math">\(V\)</span>, such that each <span id="cross-disjoint-component" class="crosslink">disjoint component</span> of <span class="math">\(p^{-1}(V)\)</span> is open and mapped <span id="cross-homeomorphically" class="crosslink">homeomorphically</span> onto V by <span class="math">\(p\)</span>
<ul>
<li>so it should not “go back” in the middle?</li>
</ul></li>
<li><span id="cross-fundamental-neighborhood" class="crosslink">fundamental neighborhood</span>, <span id="cross-path-connected" class="crosslink">path connected</span> <span id="cross-open" class="crosslink">open</span></li>
<li><span id="cross-totally-space" class="crosslink">totally space</span></li>
<li><span id="cross-base-space" class="crosslink">base space</span></li>
<li><span id="cross-fiber" class="crosslink">fiber</span> of covering <span class="math">\(p\)</span></li>
</ul>
<h3 id="unique-path-lifting">unique path lifting</h3>
<ul>
<li><span class="math">\(p: E\to B\)</span> and <span class="math">\(b\in B\)</span>, <span class="math">\(e,e'\in F_b\)</span></li>
<li>a path <span class="math">\(f: I\to B\)</span> lefts uniquely for every <span class="math">\(e\)</span> such that <span class="math">\(g(0) = e\)</span> and <span class="math">\(p\circ g = f\)</span>. the proof is actually easy</li>
<li><p>equivalent path lifts to equivalent path, and hence <span class="math">\(g(1)=g'(1)\)</span>. proof <span class="math">\(p\circ h: I\times I \to B\)</span>, compact, fundamental cover, finite cover, project back, base, finite cover, grid, grow the border (a old square only can all include the line or include nothing, so you can grow it!), inductively define the homotopy <code>fix me: i should check this proof</code></p></li>
<li>regular: <span class="math">\(p_*\)</span> project to normal group</li>
<li>universal: <span id="cross-simply-connected" class="crosslink">simply connected</span> cover</li>
<li><p>for a universal cover, <span class="math">\(F_b\)</span> are in bijective with <span class="math">\(\pi_1(B, b)\)</span></p></li>
</ul>
<h3 id="example-3">example</h3>
<ul>
<li>for <span class="math">\(n \geq 3\)</span>, <span class="math">\(\mathbf{R}P^n\)</span> covered by <span class="math">\(S^n\)</span>, then we can see that <span class="math">\(\pi_1(\mathbf{R}P^n) =2\)</span></li>
</ul>
<h3 id="cont.">cont.</h3>
<ul>
<li><span id="cross-coslice-category" class="crosslink">coslice category</span> of the groupoid</li>
<li><span class="math">\(St(x)\)</span></li>
<li>covering of groupoid</li>
<li><span id="cross-surjective" class="crosslink">surjective</span></li>
<li>restricts to bijection <span class="math">\(p:St(e)\to St(p(e))\)</span> for each <span class="math">\(e\)</span></li>
<li>the def of covering groupoid is just the useful properties of covering space. above can be reformulated as induced functor <span class="math">\(\Pi(p):\Pi(E)\to \Pi(B)\)</span> of cover space <span class="math">\(p\)</span> induce a covering groupoid</li>
<li><span class="math">\(p_*: \pi_1(E, e)\to \pi_1(B,b)\)</span> is <span id="cross-monomorphism" class="crosslink">monomorphism</span> and base changing group is <span id="cross-conjugate" class="crosslink">conjugate</span>, and as one runs though <span class="math">\(e'\)</span>, we runs through conjugate groups in <span class="math">\(\pi_1(B,b)\)</span></li>
<li>examples: i suspect all finite cover will leave the fundamental group unchanged, but in the infinite circle case, we can see that it is really monomorphism, because <span class="math">\(e\)</span> back, then <span class="math">\(b\)</span> must back, but not reverse</li>
<li>i cannot found a example that is really non-trivial conjugate, they are all surjective or not moving, i can found an example it is non-trivial subgroup, just when you cannot come back by something. for a non-trivial conjudate, see Hatcher, p58, (10)</li>
<li>run though conjugate, but still not the whole group sometimes</li>
<li>translation function <span class="math">\(T(b): \mathcal{B}\to \mathcal{Set}\)</span> (the set of fibers at a point), <span class="math">\(T(f)\)</span> is a morphism in <span class="math">\(\mathcal{Set}\)</span> which depends on <span class="math">\(f\)</span> will have different behaviour</li>
<li><p>fibers has same <span id="cross-cardinality" class="crosslink">cardinality</span></p></li>
<li>regular: <span class="math">\(p(\pi(\mathcal{E}, e))\)</span> is normal subgroup of <span class="math">\(\pi(\mathcal{B}, b)\)</span></li>
<li><p>universal: <span class="math">\(p(\pi(\mathcal{E}, e)) = \{e\}\)</span></p></li>
</ul>
<h2 id="references-3">references</h2>
<ul>
<li><span id="cross-A-Concise-Course-in-Algebraic-Topology" class="crosslink">A Concise Course in Algebraic Topology</span></li>
</ul>
<h1 id="algebra">algebra</h1>
<h2 id="notes-on-algebra">notes on algebra</h2>
<p>from the book <em>Algebra</em> by Serge Lang</p>
<h2 id="chapter-01">chapter 01</h2>
<h3 id="p003">p003</h3>
<pre><code>monoid = forall S (
    S,
    *: S * S -&gt; S,
    e: S &amp;&amp; forall a: S, a * e = e * a,
    associ: forall a b c: S, a * b * c = a * (b * c)
    )</code></pre>
<p>there are law of composition which is not associative</p>
<ul>
<li><code>-</code> in <code>integer</code></li>
</ul>
<p>there are law of composition which has no unit</p>
<ul>
<li><code>max</code> in <code>integer</code></li>
</ul>
<h3 id="p004">p004</h3>
<p>to define this product, we need <code>[0, n]</code> or lists?</p>
<pre><code>inductive nat = z | succ nat

inductive list = forall A (none | cons A (list A))</code></pre>
<p>and we might need a bunch of theorem about <code>nat</code>s and <code>list</code>s</p>
<p>but this is actually just <code>foldLeft</code>?? which is defined for <code>list</code> or linear initals?</p>
<pre><code>forall a, b: list monoid S: a.foldLeft(e, *) * b.foldLeft(e, *) = (a ++ b).foldLeft(e, *)

proof by induction</code></pre>
<p>as we understanding that elements of <code>monoid</code> is element of <code>S</code></p>
<pre><code>commutativeMonoid extends monoid (
  commu: forall a, b: S, a * b = b * a
)
</code></pre>
<h3 id="p005">p005</h3>
<p>how do we define surjection and bijection and subset now???</p>
<p><strong>fix me</strong></p>
<h3 id="p006">p006</h3>
<pre><code>forall a: monoid, n: nat: a^n = (0 until n).foldLeft(*)</code></pre>
<p>yes… there we are using <code>nat</code> again</p>
<p>is submonoid</p>
<ul>
<li>subtype? I think so, so just ommit tihs part</li>
<li>just a subobject in category theory?</li>
</ul>
<p><strong>fix me</strong></p>
<h3 id="p007">p007</h3>
<pre><code>group extends monoid (
  inverse: S -&gt; S &amp;&amp; forall a b: S: a^-1 * a = e
)

forall a: group, n: integer: a^n = if (n.positive) (0 until n).foldLeft(*, a) else (0 until -n).foldLeft(*, a^-1)</code></pre>
<pre><code>forall a: group, n, m: integer: a^n * a^m = a^(n + m)

proof by induction
</code></pre>
<h3 id="p008">p008</h3>
<h3 id="p009">p009</h3>
<pre><code>productGroup a b: group extends group (
  S = (a, b),
  (x_a, x_b) * (y_a, y_b) = (x_a * y_a, x_b * y_b),
  e = (e_a, e_b)
)</code></pre>
<p>subgroup, generators, example</p>
<p><strong>fix me</strong></p>
<h3 id="p010">p010</h3>
<pre><code>homomor A, B &lt;: group = f: A -&gt; B &amp;&amp; forall a, b: A f(a) *_B f(b) = f(a *_A b)


isomor A, B &lt;: group = homo A B &amp;&amp; exists g: homo B A: fg = id_B &amp;&amp; gf = id_A

automor A = isomor A B

endomor A = homomor A A</code></pre>
<pre><code>f: homor A B -&gt; f(a^-1) = f(a)^-1 &amp;&amp; f(e_A) = e_B
</code></pre>
<h3 id="p011---13">p011 - 13</h3>
<p>intution about normal group etc.</p>
<ul>
<li>it is force something to be equal</li>
<li>or force some elements to be e</li>
<li>if it is arbitry element? it is quotient group…?</li>
<li>if it is a group, then the all forced is just you list, but why it cannot be a group again??</li>
<li>first, you get a nice theorem of the orders of the group, this is because you are not lacking element in the forcing<br /></li>
<li>because - think of this, what if two element of <code>aH</code> product? they are not identifed in <code>aH</code> again!!!</li>
<li>we are looking for some closed structure</li>
<li>if it is a normal subgroup, we get group again</li>
<li>….???</li>
</ul>
<h3 id="p014">p014</h3>
<ul>
<li>normal group closed under intersection</li>
<li>normalizer of a subset</li>
<li>centralizer of a group</li>
</ul>
<h3 id="p015-16">p015, 16</h3>
<p>trival results</p>
<h3 id="p017">p017</h3>
<pre><code> H      HK
--- ~=~ --
H^K     K</code></pre>
<p>this means you have normalizer, you can add/subtract the irelevant dims to the problem</p>
<p>f-bar - induced normal group</p>
<h3 id="p018---20">p018 - 20</h3>
<p>towers － the refined structure of a group</p>
<p>normal/abelian/cyclic tower</p>
<p>solvable - has an abelian tower</p>
<p>finite + solvable = has an cyclic refinement</p>
<p>G solvable &lt;-&gt; G/H and H is solvable</p>
<p>commutator <code>xyx^-1y^-1</code> -&gt; it is normal and all homomor into comutative group factor through it</p>
<p>simple - nor-trival and no normal groups other than <code>{e}</code> and itself</p>
<h3 id="p021">p021</h3>
<pre><code>U, V: subgroup of g
u, v: normal subgroup of U, V

u(U^V)     (U^V)v       (U^V)
------ ~=~ ------ ~=~ ----------
u(U^v)     (u^V)v     (u^V)(U^v)</code></pre>
<h3 id="p022">p022</h3>
<p>seems no one interested in it…</p>
<p><em>Schreier</em> two normal tower ending with trival group have equivalent refinements</p>
<p><em>Jordan-Holder</em> …</p>
<p><strong>fix me</strong></p>
<h3 id="p023---25">p023 - 25</h3>
<p>so what’s the usefulness of mathematical structures? I do not know….</p>
<p>cyclic, generator, exponent of <code>a</code> or <code>G</code></p>
<p>cyclic groups: infinite period and period <code>n</code></p>
<p>propisition about finite group, prime numbers</p>
<ul>
<li>soemthing about free generated group?? don’t know…</li>
</ul>
<h3 id="p026---29">p026 - 29</h3>
<p>here we represent groups by permutations</p>
<pre><code>pi: G -&gt; Perm(S)</code></pre>
<pre><code>c_x(y) = xyx^-1</code></pre>
<p>conjugation operation, the kernel is center, subset conjugate - just moved a bit</p>
<p>isotropy - <code>G_s</code></p>
<p>isotropy group of <code>s</code> and <code>s'</code> is conjugate - this is just…</p>
<p>fixed point s: <code>G = G_s</code></p>
<p>orbit: <code>Gs</code></p>
<p>proposition 5.1 and 5.2 - they seems trivial</p>
<p>transitive - you can reach anywhere!</p>
<p>orbit decomposition formula:</p>
<pre><code>card(S) = Sum(Gs) disjoint = Sum((G: G_s_i)) &amp;&amp; Gs_i disjoint</code></pre>
<p>class formula:</p>
<pre><code>(G:1) = Sum((G: G_x))</code></pre>
<p>you should relise what the right really means</p>
<h3 id="p030---33">p030 - 33</h3>
<p>omitted</p>
<h3 id="p034---36">p034 - 36</h3>
<p>p-group: order is power of <code>p^n</code></p>
<p>p-Sylow group <code>H</code> of <code>G</code>: max <code>p^n</code> order p-subgroup</p>
<p>lemma: finite abelian group has (p | order of group) subgroup</p>
<p><em>now I know why you are talking about cyclic groups etc. the group structure is mainly complicated, and composite of simple ones like cyclic, abelian….</em></p>
<p>let’s proof by give an algorithm, because this is how it really works.</p>
<ul>
<li>first we pick an element <code>g</code> and form the cyclic group</li>
<li>if it is of order <code>q * p</code>, we set <code>h = g^q</code> and it is a cyclic group of order <code>p</code>, we are done</li>
<li>if not. we use this algorithm for <code>G/{g^a}</code>, we can show we can somehow trace over the process and get an element of order <code>p</code> in <code>G</code></li>
<li>and because <code>p|(G:1)</code>, we can see that we must get one!</li>
<li>and of course, it is finite, so our algorithm terminate</li>
</ul>
<p>something in a group:</p>
<ul>
<li>might not be a cyclic group of order <code>p</code></li>
<li>if it is a group of order <code>p</code>, it might not normal (?)</li>
</ul>
<p>Sylow theorem 1: p-Sylow group always exists</p>
<p><em>again, we need recursion!!!</em></p>
<ul>
<li>we should make the problem smaller</li>
<li>frist, <code>c = center(G)</code></li>
<li>if <code>c</code> is trivial, then because class formula, we has a subgroup contains all <code>p</code>, proofed</li>
<li>if <code>c</code> is not trivial, no matter what stucture <code>c</code> have, we can always made into subgroups, and <code>G/c</code> is a smaller subgroup, proofed</li>
<li>we should not divide by “all subgroup diviable by <code>p</code>”, it is no inuation here</li>
</ul>
<p>lemma: for p-group <code>H</code> on finite set <code>S</code>, <code>number of fix points == #(S) mod p</code></p>
<p>Sylow theorem 2:</p>
<ul>
<li>p-supgroup is subgroup of p-Sylow group</li>
<li>all p-Sylow group are conjugate</li>
<li>number of p-Sylow group == 1 mod p</li>
</ul>
<p>Sylow theorem 3: finite p-group is solvable, and has non-trival center</p>
<p>lemma: smallest prime group is normal</p>
<p>proposition: group of order <code>pq</code> is solvable</p>
<p><strong>fix me</strong></p>
<h3 id="p037---41">p037 - 41</h3>
<p>direct sum: product with only finite non-zero dim</p>
<p><code>lambda_i</code> injection</p>
<hr />
<p><strong>by far, algebra is self contained. the things like <code>nat</code>, etc. is just basic like product type, and there really are nothing not grounded into the foundation!!! it is so good!!!</strong></p>
<hr />
<p>proposition, universal property of direct sum: <code>f_i</code> into abelian <code>B</code> to induce a <code>f</code> from <code>(+)A_i</code> to <code>B</code></p>
<pre><code>basis abelian = generator &amp;&amp; unique

(free = exists basis) abelian ~=~ (+)Z_i
</code></pre>
<p>the fucking diagram</p>
<p>free abelian group generated by <code>S</code></p>
<p>grothendieck group - the universal group from commutative monoid to group</p>
<p><strong>fix me</strong></p>
<p>lemma 7.2: projection to free group has finer structure</p>
<p>theorem 7.3: subgroup of free abelian group is free-abelian. base has same cardinal. and it is called rank</p>
<p><strong>notice that finite abelian is finite generated, so our theorem has…</strong></p>
<h3 id="p042---46">p042 - 46</h3>
<p>we only consider abelian group</p>
<p>torsion, torsion subgroup, torsion group, <code>A(p)</code></p>
<p>theorem 8.1 torsion abelian group is <code>(+)_p A(p)</code></p>
<p>finite p-group <code>A</code> of type <code>(p^r_1, p^r_2, ...)</code></p>
<p>theorem: finite abelian group has type</p>
<p>proof:</p>
<ul>
<li>find a element and get the cyclic group!</li>
</ul>
<p><strong>fix me</strong></p>
<p>theorem 8.4: finite generated torsion-free group is free</p>
<p>theorem 8.5: finite generated abelian group is direct sum of torsion-subgroup and torsion-free subgroup</p>
<p>rank of finite generated group (the rank of free part)</p>
<h3 id="p047---49">p047 - 49</h3>
<p>the dual group</p>
<ul>
<li>for abelian group of exponent <code>m</code></li>
<li><code>A^ = Hom(A, Z_m)</code> is the dual</li>
</ul>
<p>same exponent <code>m</code> group <code>A</code> and <code>B</code>’s homomor <code>f</code> will induce <code>f^: B^ -&gt; A^</code></p>
<p>theorem: finite abelian group direct sums’s structure is isomorphic to the dual one, and <code>A</code> is isomorphic to <code>A^</code></p>
<p>to proof the second part, make <code>A</code> cyclic, and observe that a cyclic group homo is just…</p>
<p>bilinear map <strong>fix me</strong></p>
<h3 id="p050---52">p050 - 52</h3>
<p>inverse limit</p>
<p>completion</p>
<p><strong>fix me</strong></p>
<h3 id="p53---65">p53 - 65</h3>
<p>category</p>
<p>morphisms</p>
<p>isomorphism</p>
<p>automorphism</p>
<p>endomorphism</p>
<p>universally attracting: every and unique</p>
<p>universeally repelling: every and unique</p>
<p>product: direct sum</p>
<p>coproduct:</p>
<p><strong>fix me</strong></p>
<h3 id="p066---74">p066 - 74</h3>
<p>free group generated by <code>S</code></p>
<p>theorem: free group exists</p>
<p>theorem: coproduct exists</p>
<p><strong>fix me</strong></p>
<h2 id="chapter-01-exercises">chapter 01 EXERCISES</h2>
<ol style="list-style-type: decimal">
<li><p>show that every grouop of order &lt;= 5 is abelian</p>
<p>p-group is solvable and has non-trival center</p></li>
<li><p>trivial</p></li>
<li><p>trivial</p></li>
<li><p>trivial</p></li>
<li><p>proof a iso?</p></li>
<li><p>trivial</p></li>
<li><p>turn <code>a</code> into <code>b</code> in <code>aba^-1=b</code></p></li>
<li><p><strong>fix me</strong></p></li>
<li><p>if group has finite index subgroup, then there is finite index normal subgroup &amp;&amp; finite index intersection is finite index</p>
<p><strong>fix me</strong></p></li>
<li><p>right coset number is equal to left coset</p>
<p>inverse!!!</p></li>
<li><p><strong>fix me</strong></p></li>
</ol>
<p><strong>fix me</strong></p>
<h2 id="chapter-02">chapter 02</h2>
<h3 id="p083---92">p083 - 92</h3>
<p>ring - abelian group of plus and monoid multiplication and <code>(x + y)z = xz + yz</code></p>
<ul>
<li>think distributivity kind of weeken linearization*</li>
</ul>
<p><code>U</code> the set of elements who has right and left inverse is a group, group of units in <code>A</code></p>
<p>division ring</p>
<ul>
<li>it must be two sided, think them as functions, and think of shift operator</li>
</ul>
<p>commutative ring</p>
<p>commutative &amp;&amp; division ring = field</p>
<p>subring = subgroup of additive group &amp;&amp; submonid of multi</p>
<ul>
<li>it seems that finding subring is harder than finding sub group, one should use distributive law to find them</li>
<li>center is subring</li>
<li>example</li>
<li><code>Z</code></li>
<li>addtive group endormors is a ring of add and compo</li>
<li><code>Map(S,A)</code> into ring <code>A</code></li>
<li>matrix</li>
<li>polynomials</li>
<li>convolution product of a group ring</li>
<li><code>(f*g)(z) = Sum(f(x)g(y) | xy = z)</code></li>
</ul>
<p>left ideal: subgroup of additive group &amp;&amp; <code>Aa = a</code></p>
<p>right ideal</p>
<p>ideal</p>
<ul>
<li><code>Aa</code> is left ideal. called principal</li>
<li>also <code>A(a, b, c)</code> etc. generator of the left ideal</li>
</ul>
<p>intersection of ideal is ideal. also for left ideal</p>
<ul>
<li>commutative ring left ideal = ideal</li>
</ul>
<p>principal ring = commutative &amp;&amp; every ideal is principal</p>
<ul>
<li>the ring that every ideal is single generated?</li>
</ul>
<p>ideals</p>
<ul>
<li>is a multiplicative monoid, the unit is <code>A</code> is unit ideal, <code>(1)</code>, also for left ideals</li>
<li>is addtive monoid</li>
<li>but is not a ring!</li>
<li>left ideal <code>a</code> =&gt; <code>aA</code> is ideal</li>
<li>for two ideal, <code>ab &lt; a^b</code></li>
</ul>
<p>ring-homormor, kernel = additive kernel</p>
<ul>
<li>the kernel is ideal - it is maped to zero the repeller!!</li>
</ul>
<p>and we have factor ring and canonical map, and it is universal</p>
<p>prime ideal</p>
<ul>
<li><code>ab</code> in <code>P</code> then <code>a</code> or <code>b</code> in <code>P</code></li>
<li><code>P != R</code></li>
</ul>
<p>a useful sport: map from <code>Z</code> to <code>A</code> by <code>ne</code></p>
<ul>
<li>the kernel is an ideal of <code>Z</code>: <code>(n)</code></li>
<li>we have a injective homomor <code>Z/nZ -&gt; A</code></li>
<li>if <code>n</code> prime, <code>n</code> match</li>
<li>case <code>0</code>: <code>A</code> characteristic <code>0</code>, it has subring <code>Z</code></li>
<li>case <code>n</code> prime: <code>A</code> characteristic <code>p</code>, contains substring <code>Z/pZ = F_p</code></li>
<li>if in field <code>K</code>, it contains <code>Q</code> or <code>F_p</code>. they are called prime field in <code>K</code></li>
<li>by prime ring in <code>K</code> we means <code>Z</code> or <code>F_p</code></li>
</ul>
<p>let <code>A</code> a subring of <code>B</code> and <code>S</code> a subset of <code>B</code> that commuting with <code>A</code> then we have <code>A[S] = {a s s s s}</code>. if <code>B = A[S]</code> we say that <code>B</code> is generated by <code>S</code> over <code>A</code>. if <code>S</code> is finite, then finite generated.</p>
<ul>
<li>one might say that <code>A[S]</code> consists all not-necessory commutative polynomials in elements of <code>S</code> with coeffients in <code>A</code></li>
<li>elements of <code>S</code> may not commute!!</li>
<li>example: matrices, when <code>A</code> is <code>nI</code></li>
<li>homomorphism is determined by its effect on generators</li>
</ul>
<p>residue class ring, residue class modulo <code>a</code>, <code>x === y (mod a)</code></p>
<p>induced homomor by ideal in <code>A'</code>, product exists in <code>Ring</code></p>
<p>zero divisors: <code>x != 0 &amp;&amp; y != 0 &amp;&amp; xy == 0</code></p>
<p>entire: <code>1 != 0</code> &amp;&amp; commutative &amp;&amp; no zero divisors</p>
<p>theorem: for entire ring, <code>a</code>, <code>b</code> generate same ideal if there is a unit such that <code>b = au</code></p>
<ul>
<li>the bijective proof is injective for normal ring</li>
</ul>
<h3 id="p093-97">p093 － 97</h3>
<p><em>only discuss commutative ring!!!</em></p>
<ul>
<li>prime = <code>p</code> &amp;&amp; <code>A/p</code> entire =~= <code>xy in p =&gt; x in p || y in p</code></li>
<li>maximal ideal: no bigger</li>
<li>maximal =&gt; prime</li>
<li>every ideal is contained in some maximal</li>
<li>field has only 2 ideal</li>
<li><code>m</code> maximal &lt;=&gt; <code>A/m</code> field</li>
<li>homomor <code>f</code>, prime, maximal</li>
<li>example</li>
<li><code>Z</code>: <code>x^(p-1) == 1(mod p)</code> － using</li>
<li>Chinese remainder theorem: <code>a_n</code> be ideals <code>a_i + a_j = A</code>, then for <code>x_n</code> exists <code>x</code>: <code>x == x_i (mod a_i)</code></li>
<li>read the proof</li>
<li><code>a_1^(v_1) + ... = A</code> problem <strong>fix me</strong></li>
<li><code>A/^(a_i) ~=~ *(A/a_i)</code></li>
<li><strong>fix me</strong></li>
</ul>
<h3 id="p098---107">p098 - 107</h3>
<ul>
<li>polynomial over a ring <code>A</code></li>
<li>polynomial function ring homomor <code>ev_b: A[X] -&gt; B</code></li>
<li><code>x</code> is transcendental over <code>A</code></li>
<li><code>f -&gt; gf</code> the reduction map</li>
<li>reduction of <code>f</code> modulo <code>p</code></li>
<li>degree, linear, leading coefficient, constant</li>
<li>assume <code>A</code> commutative</li>
<li><code>deg(fg) = deg f + deg g</code> if <code>a_n</code> and <code>b_m</code> is not zero
<ul>
<li><code>A</code> entire =&gt; <code>A[X]</code> entire</li>
</ul></li>
<li>polynomials in n variables
<ul>
<li>algebraically independent</li>
<li>degree</li>
<li>homogeneous</li>
<li><code>deg(fg) = deg(f) + deg(g)</code></li>
</ul></li>
<li><code>A</code> a commutative ring, <code>G</code> a monoid. group ring or moniod ring - polynomials is special case!</li>
<li>get all <code>G -&gt; A</code> which is almost zero</li>
<li>we get a ring</li>
<li>and eval reduce in the ring <strong>fix me?</strong></li>
</ul>
<h3 id="p108---110">p108 - 110</h3>
<ul>
<li>multiplicative subset: has 1 and closed by *</li>
<li>quotient ring, ring of fraction of <code>A</code> by <code>S</code></li>
<li><code>(a, s) ~ (a', s')  := exists s_1 (s'a-sa') = 0</code></li>
<li>is equiv</li>
<li><code>a/s</code> and <code>S^-1/A</code></li>
<li><code>a/s * a'/s' = aa'/ss'</code></li>
<li><code>a/s + a'/s' = (s'a + sa') / ss'</code></li>
<li>it is a ring</li>
<li><code>A -&gt; S^-1A</code>
<ul>
<li>f(s) is invertable</li>
<li>and the homomor is universal</li>
</ul></li>
<li>if <code>A</code> is entire =&gt; it is injective</li>
<li>examples</li>
<li>quotient field</li>
<li>rational function</li>
<li>defined at b</li>
<li>local ring: commutative and unique maximal ideal</li>
<li><strong>fix me</strong></li>
</ul>
<h3 id="p111---114">p111 - 114</h3>
<ul>
<li>factorial (unique factorization ring)</li>
<li>divides</li>
<li>gcd</li>
<li>order</li>
<li>prime</li>
<li>lcm</li>
<li><strong>fix me</strong></li>
</ul>
<h2 id="chapter-02-exercises">chapter 02 EXERCISES</h2>
<p><strong>fix me</strong></p>
<h2 id="chapter-03">chapter 03</h2>
<h3 id="p117">p117</h3>
<p><em>thinking in vs!</em></p>
<p><em>and by module, it is itself a abelian group first!</em></p>
<ul>
<li><code>M</code> is left module over <code>A</code></li>
<li>abelian group</li>
<li>ops of <code>A</code> on <code>M</code></li>
<li>distributive</li>
<li>examples</li>
<li><code>A</code> is module over itself</li>
<li>commutative group is Z-module</li>
<li>left ideal of <code>A</code> is module over <code>A</code></li>
<li>submodule <code>N</code>: <code>AN &lt; N</code></li>
<li>module over field = vector space</li>
<li>the ring is the field, scalar</li>
<li>linear map over vs is a module</li>
<li>because linear, the <code>a(x+y) = ax + ay</code> is possible</li>
<li><code>A</code> entire, torsion submodule <code>M_tor</code>: <code>ax = 0 &amp;&amp; a != 0</code></li>
<li>factor module</li>
<li>hodule-homomor <code>f: M -&gt; M'</code></li>
<li>over the same ring <code>A</code></li>
<li>additive group homomorphism</li>
<li><code>f(ax) = af(x)</code></li>
<li>also <code>A</code>-homomor or <code>A</code>-linear map</li>
<li>zero homomor</li>
<li>kernel and image is submodule</li>
<li>cokernel <code>M'/Im f</code></li>
<li>the group canonical homos applies equally in module</li>
<li>exact <code>Im f = Ker g</code>: <code>M' -f-&gt; M -g-&gt; M''</code></li>
<li>monomorphism, embedding: <code>0 -&gt; N -u-&gt; M</code></li>
<li>epimorphism: <code>N -u-&gt; M -&gt; 0</code></li>
<li>there are algebras…</li>
<li>no unit</li>
<li>no assco but distributive</li>
<li>bilinear map</li>
<li>A-algebra, module + bilinear map <code>g: E * E -&gt; E</code></li>
<li><strong>fix me</strong></li>
</ul>
<h3 id="p122--">p122 -</h3>
<ul>
<li><code>A</code> a ring, and <code>X</code>, <code>X'</code> be <code>A</code>-modules, <code>Hom_A(X', X)</code> is abelian group</li>
<li>if <code>A</code> is commutative, then <code>Hom_A</code> is <code>A</code>-module, the group action is <code>a(f) -&gt; af</code></li>
<li><code>Hom_A</code> is also a functor, contravariant in first variable. covariant in second</li>
</ul>
<p><strong>fix me!!!</strong> I fear the category things!</p>
<h2 id="chapter-04-polynomials">chapter 04 polynomials</h2>
<h3 id="p174--">p174 -</h3>
<ul>
<li>Euclidean algorithm: <code>f = gq + r</code> if leading coefficient of <code>g</code> is unit</li>
<li>zero of a polynomial</li>
<li><code>k</code> be a field =&gt; <code>k[X]</code> is principal &amp;&amp; factorial</li>
<li>irrducible <code>f in k[X]</code>: degree &gt;= 1 and not a product <code>f = gh &amp;&amp; g, h !in k</code></li>
<li>monic</li>
<li>at most n roots, and <code>X - a</code> divides <code>f</code></li>
</ul>
<p><strong>fix me!!!</strong></p>
<h2 id="chapter-05-algebraic-extensions">chapter 05 algebraic extensions</h2>
<p>it studies things <strong>algebraic</strong></p>
<h2 id="definition-3">definition</h2>
<ul>
<li><p><span id="cross-abelian" class="crosslink">abelian</span></p></li>
<li><span id="cross-monoid" class="crosslink">monoid</span></li>
<li><span id="cross-group" class="crosslink">group</span>
<ul>
<li><span id="cross-abelian-group" class="crosslink">abelian group</span> <span class="math">\(\mathcal{Ab}\)</span></li>
</ul></li>
<li><span id="cross-groupoid" class="crosslink">groupoid</span>
<ul>
<li>groupoid connected
<ul>
<li>can be viewed as <span id="cross-category-connected" class="crosslink">category connected</span>, then the groupoid viewed as a <span id="cross-category" class="crosslink">category</span> will have <span id="cross-skeleton-category" class="crosslink">skeleton category</span> one element with full <span id="cross-isomorphism" class="crosslink">isomorphism</span></li>
</ul></li>
</ul></li>
<li><span id="cross-ring" class="crosslink">ring</span></li>
<li><span id="cross-module" class="crosslink">module</span></li>
<li><p><span id="cross-vector-space" class="crosslink">vector space</span></p></li>
</ul>
<h3 id="group-action">group action</h3>
<ul>
<li>isotropy group
<ul>
<li>for <span class="math">\(s\in S\)</span> the subgroup <span class="math">\(G_s = \{g|gs=s\}\)</span></li>
</ul></li>
<li>group action <span class="math">\(G\times S\to S\)</span>, such that <span class="math">\(e s = s\)</span> and <span class="math">\(g^' g s = (g g^')s\)</span> for all <span class="math">\(s\)</span></li>
<li><span id="cross-isotropy-group" class="crosslink">isotropy group</span></li>
<li><span id="cross-free-action" class="crosslink">free action</span> if <span class="math">\(G_s\)</span> is all trivial</li>
<li><span id="cross-orbit" class="crosslink">orbit</span> <span class="math">\(G s\)</span></li>
<li><span id="cross-transitive-action" class="crosslink">transitive action</span> <span class="math">\(\forall s, s^'\exists g: g s = s^'\)</span>, or there is single orbit
<ul>
<li><span id="cross-subgroup" class="crosslink">subgroup</span> <span class="math">\(H\)</span>, then <span id="cross-coset" class="crosslink">coset</span> <span class="math">\(gH\)</span> is a transitive <span class="math">\(G\)</span>-set</li>
<li>when <span class="math">\(G\)</span> works transitively, there is an <span id="cross-isomorphism" class="crosslink">isomorphism</span> of <span class="math">\(G\)</span>-set between <span class="math">\(S\)</span> and <span class="math">\(G/G_s\)</span> for any <span class="math">\(s\)</span> by <span class="math">\(g s\leftrightarrow g G_s\)</span></li>
</ul></li>
<li>category <span class="math">\(\mathcal{O}(G)\)</span> of canonical orbits
<ul>
<li>object: <span class="math">\(G\)</span>-sets <span class="math">\(G/H\)</span></li>
<li>morphism: <span class="math">\(G\)</span>-map: function <span class="math">\(f\)</span> such that <span class="math">\(f(g s) = g f(s)\)</span></li>
<li>if <span class="math">\(G\)</span> is transitively on <span class="math">\(S\)</span>, choose <span class="math">\(s\in S\)</span>, and <span class="math">\(H= G_s\)</span>, <span id="cross-Weyl-group" class="crosslink">Weyl group</span> <span class="math">\(W_H\)</span> is <span id="cross-isomorphism" class="crosslink">isomorphism</span> to group <span class="math">\(Aut_G(S)\)</span> of automorphism of <span class="math">\(S\)</span></li>
<li>a <span class="math">\(G\)</span>-map <span class="math">\(\alpha:G/H\to G/K\)</span> has form <span class="math">\(\alpha(g H)= g \gamma K\)</span> and <span class="math">\(\gamma\in G\)</span> that <span class="math">\(\gamma^{-1}h \gamma\in K\)</span> for all <span class="math">\(h\in H\)</span> <code>fix me</code></li>
<li>the category <span class="math">\(\mathcal{O}(G)\)</span> is isomorphism to <span class="math">\(\mathcal{G}\)</span> with objects subgroups of <span class="math">\(G\)</span> and morphisms distinct subconjugacy relations <span class="math">\(\gamma^{-1}H\gamma\subset G\)</span> for <span class="math">\(\gamma\in G\)</span></li>
</ul></li>
</ul>
<h2 id="references-4">references</h2>
<h1 id="real-and-functional-analysis">real and functional analysis</h1>
<p>from the book <em>Real and Functional Analysis</em> by Serge Lang</p>
<p>prerequests include first chapters of <em>Set Theory</em> by Jech, but sense we take a type theoritic foundation and this foundation is not done yet, we ignore them…</p>
<ul>
<li>might be useful: <a href="http://www.math.wustl.edu/~victor/classes/ma5051/">http://www.math.wustl.edu/~victor/classes/ma5051/</a></li>
</ul>
<h2 id="chapter-01-sets">chapter 01 sets</h2>
<p>they are trivial</p>
<ul>
<li>demumerable -&gt; <code>|A| = omega</code></li>
<li>countable -&gt; <code>|A| &lt;= omega</code></li>
<li>Zorn’s lemma</li>
</ul>
<h2 id="chapter-02-topological-spaces">chapter 02 topological spaces</h2>
<p><em>what’s the point in studying point set topology theory? because there are so many topological truth!!! you can view something as a ts in a weak sense and get results!</em></p>
<p><em>yes. hott is a better foundation for homotopy theory, but… what ever… just learn them</em></p>
<ul>
<li>there will always be a weaker notation for topological facts in seq</li>
<li><em>just like computer engineering, some theorem is just mere facts.</em>
<ul>
<li>they are not intelegently chanllenged</li>
<li>but it takes time to remember them
<ul>
<li>but actually you do not need them that important</li>
</ul></li>
<li>you should build a system to memeorize them
<ul>
<li>by intuition</li>
</ul></li>
<li>they are kind of hard work, just!</li>
</ul></li>
<li>topics
<ul>
<li>general topology space</li>
<li>Hausdorff space</li>
<li>matric space</li>
<li>normal space</li>
<li>normed space</li>
</ul></li>
</ul>
<hr />
<ul>
<li>topology</li>
<li>open sets (finite intersection and arbitrary union)</li>
<li>metric
<ul>
<li>define <code>d(a, b)</code> into <code>R</code></li>
<li>positive and <code>d(a, b) == 0 &lt;-&gt; a = b</code></li>
<li><code>d(a, b) = d(b, a)</code></li>
<li><code>d(x, y) &lt;= d(x, z) + d(z, y)</code></li>
<li>a norm induce a matric</li>
<li>open, closed ball, sphere</li>
<li>Cauchy seq</li>
<li>seq converge</li>
<li>complete - Cauchy seq converge</li>
<li>matric space can always embeded into nvs
<ul>
<li>how about a discrete matric??</li>
</ul></li>
</ul></li>
<li>normed vector space (over <code>R</code> or <code>C</code>)
<ul>
<li>define a function to <code>R</code></li>
<li><code>|x| &gt;= 0</code> and only <code>= 0</code> if <code>x = 0</code></li>
<li><code>|cx| = |c||x|</code></li>
<li><code>|x+y| &lt;|x| + |y|</code></li>
<li>eg.
<ul>
<li>sup norm
<ul>
<li>uniformly cauchy / convergent</li>
</ul></li>
<li>L^1-norm
<ul>
<li>L^1-Cauchy / convergent</li>
</ul></li>
</ul></li>
<li>norm equvi - give same topo - <code>C_1|x|_1 &lt;= |x|_2 &lt;= C_2|x|_1</code></li>
</ul></li>
<li>topology equvi</li>
<li>closed set</li>
<li><code>x</code> adherent to subset <code>S</code>, every neibor overlay <code>S</code></li>
<li>boundary = adherent to <code>S</code> and <code>-S</code></li>
<li>interior point</li>
<li>theorem: closed = include boundary</li>
<li>closure: S + boundary, <code>S-bar-bar = S-bar</code></li>
<li>theorem: <code>S-bar \/ T-bar = (S \/ T)-bar</code>, <code>(S^T)-bar &lt; S-bar ^ T-bar</code> <em>there are two kind of method to gain something, and they are comutative, but when talking about lose and gain, they are not!</em></li>
<li><code>S &lt; X</code> dense in <code>X</code> := <code>S-bar = X</code></li>
<li>induced topology on subset, subspace</li>
<li>base - every open set is a union of <em><code>B</code></em></li>
<li>if
<ul>
<li>every point in <code>B</code></li>
<li>closed by <code>&lt;</code> for <code>^</code></li>
<li>then it is a base and define a topology</li>
</ul></li>
<li>refinement, coarser</li>
<li>weak topology generated by <code>F</code> - topology generated by <code>f^-1(W)</code> as base</li>
<li>separable - has countable base - <em>compressing properties</em></li>
<li>neighborhood</li>
<li>continuous, and continuous at point <code>x</code>
<ul>
<li>in matric space, it is <code>(epsilon, delta)</code> definition</li>
</ul></li>
<li>continuous is preserved by <code>*</code></li>
<li>homeomorphism - topological isomorphism != continuous bijective map</li>
<li>product topology - the weak topology induced by projection</li>
<li>open map: open -&gt; open, closed map: closed -&gt; closed
<ul>
<li>a continuous can be neither</li>
<li><em>because we are really cared about the value</em></li>
</ul></li>
<li>connected - !disjoint union of open set</li>
<li>continuous map perseve connecteness</li>
<li>prop 2.3: family of subspace connected &lt;-&gt; has common point. connected component of a point <code>a</code></li>
<li>prop: <code>S</code> connected then <code>S&lt; T&lt; S-bar</code> is connected. <em>you are adding boundary points!!!</em></li>
<li><em>these propersition is just like… toys.</em></li>
<li>path connected - has piecewise continuous path for all points - or has continuous from <code>[0, 1]</code>,
<ul>
<li>any interval of <code>R</code> is connected</li>
<li>path connected -&gt; connected</li>
<li>reverse? - consider the comb! or…</li>
</ul></li>
<li>arc connected - by a hemeomorphism
<ul>
<li>example of path but not arc - <code>0</code> and <code>0'</code> in <code>R^+</code>, <em>wikipedia</em></li>
<li>Hausdorff space equal</li>
</ul></li>
<li>product preserve connectedness
<ul>
<li>actually I can proof by using the product base, and for infinite space, it is easier…</li>
</ul></li>
<li>covering of <code>X</code> in set!!!, open covering, closed covering</li>
<li>compact = any open covering has finite subcovering = any family of closed set have finite intersection property =&gt; infinite intersection is also non-empty
<ul>
<li><em>what means? travel by open cover?</em></li>
</ul></li>
<li>reletively compact = closure is compact</li>
<li>couninuous perserve compactness</li>
<li><strong>closed subspace of compact is compact</strong></li>
<li>Hausdorff = unequal points has two disjoint open nei
<ul>
<li>metric space is normal Hausdorff</li>
</ul></li>
<li><strong>compact subspace of Hausdorff space is closed</strong></li>
<li>normal = disjoint closed set has open disjoint nei</li>
<li>compact disjoint subset of Hausdorff space has disjoint nei =&gt; (compact Hausdorff =&gt; normal)</li>
<li>subspace of Hausdorff space is Hausdorff
<ul>
<li>not true for normal</li>
</ul></li>
<li>sequentially compact = every sequence has a point of accumulation (every nei has infinite <code>x</code>)
<ul>
<li><em>you are not going too far away!!!</em></li>
<li><em>so actually compact is a stronger condition!</em></li>
<li><em>this def is not same as the wikipedia one!!!</em></li>
<li>compact =&gt; seq compact</li>
<li>countable base &lt;=&gt; compact = seq compact
<ul>
<li>proof: open cover =&gt; countable cover =&gt; unique point cover =&gt; must finite =&gt; if not =&gt; acc point!</li>
</ul></li>
<li>in a metric space
<ul>
<li>compact == seq compact == complete &amp;&amp; forall <code>r</code> exists finite open ball of <code>r</code> cover (totally bounded)
<ul>
<li>proof: matric =&gt; seq compact == compact =&gt; complete &amp;&amp; totally bounded || <strong>the proof is intricate!, it should really be a memorized technical lemma!!</strong></li>
<li>subset of complete metric space (totally bounded =&gt; reletively compact)</li>
</ul></li>
</ul></li>
</ul></li>
<li>in <code>R</code>
<ul>
<li>above theorems =&gt; norm space =&gt; seq version =&gt; ordering properties</li>
<li><code>f</code> <strong>continuous</strong> on compact set has max</li>
</ul></li>
<li><code>f: A -&gt; F</code> compact subset of matric space -&gt; matric space=&gt; continuous = uniform continuous. proof using <code>r</code> has min, because it is compact -&gt; R, so compact</li>
<li><strong>Tychonoff’s</strong> product preserve compact</li>
<li>in finite dim vector space
<ul>
<li><strong>compact = closed and bounded</strong> (instead of totally bounded)</li>
<li>all norm is equivalent</li>
<li>normed vector space locally compact iff finite dim</li>
</ul></li>
<li>locally compact (the proof is locally compact =&gt; finite dim!!!!)
<ul>
<li>one point compactification</li>
<li><code>R^n -&gt; R^(n+1)-sphere</code></li>
</ul></li>
<li>separation by continuous functions</li>
<li><code>X</code> normal space
<ul>
<li><code>A</code> closed, <code>U</code> open =&gt; <code>A &lt; U_1 &lt; U_1-bar &lt; U</code></li>
<li>Urysohn’s lemma: <code>A</code>, <code>B</code> be closed disjoint subset, then separatable by continuous functions in <code>[0, 1]</code> with, <code>f(A) = 0</code> and <code>f(B) = 1</code></li>
<li>the locally compact Hausdorff case</li>
<li>Tietze extension theorem</li>
</ul></li>
</ul>
<h2 id="chapter-02-exercises-1">chapter 02 EXERCISES</h2>
<ol style="list-style-type: decimal">
<li><ol style="list-style-type: decimal">
<li>using the comapact to proof closed =&gt; continuous</li>
<li>extension by limit?</li>
</ol></li>
<li><ol style="list-style-type: decimal">
<li>trivial</li>
<li>trivial</li>
<li>trivial</li>
<li>trivial</li>
</ol></li>
<li><ol style="list-style-type: decimal">
<li>seems very complicated….</li>
<li>.</li>
</ol></li>
<li><ol style="list-style-type: decimal">
<li>.</li>
<li>.</li>
</ol></li>
<li>metrizable, compatible
<ol style="list-style-type: decimal">
<li>trivial</li>
<li>trivial</li>
<li>trivial</li>
</ol></li>
<li>trivial</li>
<li><ol style="list-style-type: decimal">
<li>trivial</li>
<li><a href="http://en.wikipedia.org/wiki/Metrization_theorem">http://en.wikipedia.org/wiki/Metrization_theorem</a></li>
</ol></li>
<li>.</li>
<li>.</li>
<li>trivial</li>
<li>trivial</li>
<li>path connected in normed vector space is open!!! this is the point!!!</li>
<li>.</li>
<li><ol style="list-style-type: decimal">
<li>.</li>
<li>.</li>
<li>.</li>
<li>using the normed vector space, path connected = connected</li>
</ol></li>
<li>trivial</li>
<li>.</li>
<li>.</li>
<li>.</li>
<li>.</li>
<li></li>
</ol>
<h2 id="chatper-03-continuous-functions-on-compact-spaces">chatper 03 continuous functions on compact spaces</h2>
<p><em>real valued functions?</em></p>
<ul>
<li>Banach space = complete normed vector space</li>
<li>algebra on <code>X</code> <strong>to <code>R</code> or <code>C</code></strong>: difference of <code>xf in A</code></li>
<li>example of algebra: <code>C(X)</code>, polynomials</li>
<li>separates points</li>
<li>Stone-Weierstrass theorem: on compact set <code>S</code> an algebra <code>A</code>
<ul>
<li>separate points + contains constant &lt;=&gt; uniform closure is <code>C(S)</code></li>
<li>complex version, <code>A</code> additionally self conjugate, same result</li>
<li>proof: first under the max, min, we can approx using compact, second, we can approx abs using poly. in complex version, we have conjugate to proof the real valued ones separate points, then we use real valued to approx complex valued</li>
</ul></li>
<li>ideal of an algebra</li>
<li><code>Z_f</code> zeros of a continuous function is closed</li>
<li><code>Z(J) = ^(Z_f)</code></li>
<li>theorem 2.1: <code>X</code> an compact space, <code>R</code> ring of continuous function on <code>X</code>, with sup norm. <code>J</code> a closed ideal. <code>f in R &amp;&amp; f(x) = 0 forall x in Z(J)</code> =&gt; <code>f in J</code>
<ul>
<li>it created a semi-constant in <code>J</code></li>
<li><em>understand what the theorem says, if you have a closed ideal, then almost all function that zeros in the zero of the ideal will in the ideal!!!</em></li>
</ul></li>
<li><code>X</code> metric space, <code>F</code> a Banach space, <code>O</code> subset of <code>C(X,F)</code> (equicontinuous at <code>x_0</code> = <code>forall e, exists t (d(x, x_0) &lt; t =&gt; forall f in O: |f(x)-f(x_0)| &lt; e)</code>)</li>
<li><strong>Ascoli’s</strong>: with above &amp;&amp; <code>X</code> compact, <code>O</code> using sup norm (<code>O</code> is relatively compact in <code>C(X,F)</code> &lt;=&gt; <code>O</code> is equicontinuous &amp;&amp; <code>forall x in X, O(x)={f(x)} relatively_compact</code>)
<ul>
<li>if <code>F</code> is <code>R</code> or <code>C</code>, we use bounded</li>
<li>corollary 3.3 <strong>fix me</strong></li>
<li><em>it is that you can use open ball if they are about as one function: same rate and not too far away in values</em></li>
</ul></li>
<li>example of incomplete normed vector space?
<ul>
<li><a href="http://math.stackexchange.com/questions/209665/series-in-incomplete-normed-space">http://math.stackexchange.com/questions/209665/series-in-incomplete-normed-space</a></li>
</ul></li>
</ul>
<h2 id="chapter-03-exercises">chapter 03 EXERCISES</h2>
<ol start="0" style="list-style-type: decimal">
<li>construct the function =&gt; proof it is the limit =&gt; proof it is continuous</li>
<li>.</li>
<li>.</li>
<li>.</li>
<li>.</li>
<li>.</li>
<li>.</li>
<li>.</li>
<li>.</li>
<li>.</li>
<li>.</li>
<li>using the ws theorem</li>
</ol>
<h2 id="chapter-04-banach-spaces">chapter 04 Banach spaces</h2>
<ul>
<li><code>{a_n} &gt;= 0</code> such that <code>Sum(a_n)</code> converges (in <strong>Banach</strong> space <code>|x_n| &lt;= a_n</code> for all <code>n</code>, then <code>Sum(x_n)</code> converges)</li>
<li>normed vector space: linear map <code>l: E -&gt; F</code> continuous &lt;=&gt; <code>exists C &gt; 0, |l(x) &lt;= C|x| forall x in E</code>
<ul>
<li>example of non-continuous linear map: <a href="http://en.wikipedia.org/wiki/Linear_map#Continuity">http://en.wikipedia.org/wiki/Linear_map#Continuity</a></li>
<li><a href="http://en.wikipedia.org/wiki/Discontinuous_linear_map">http://en.wikipedia.org/wiki/Discontinuous_linear_map</a></li>
<li>=&gt; is… obv, &lt;= is same</li>
<li><code>C</code> is bound of <code>l</code>, <code>l</code> is bounded</li>
<li>lub of all <code>|l(x)|</code> on <code>S_1</code> = norm of <code>l</code></li>
<li><code>l -&gt; |l|</code> is norm on <code>L(E, F)</code> (<strong>continuous</strong> linear map)</li>
<li><code>|u*v| &lt;= |u||v|</code> for <code>L</code> map composition</li>
</ul></li>
<li><code>F</code> complete =&gt; <code>L(E, F)</code> complete</li>
<li>operator: <code>E -&gt; E</code> &amp;&amp; clm</li>
<li>invertible = toplinear isomorphisms, <code>Lis(E, F)</code></li>
<li>automorphism <code>Laut(E)</code></li>
<li>Banach isomorphism, isometry: <code>|u(x)| = |x|</code></li>
<li>bilinear: for normed vector space <code>E</code>, <code>F</code>, <code>G</code>, <code>l: E * F -&gt; G</code> is linear for two components
<ul>
<li>bilinear continuous &lt;=&gt; <code>|l(x, y)|&lt;C|x||y|</code></li>
<li>norm of bilinear, <code>L(E, F; G)</code></li>
<li>and <code>G</code> complete =&gt; <code>L(E, F; G)</code> complete</li>
<li>examples: matrix mul, dot product, cross product</li>
</ul></li>
<li>iso between <code>L(E, L(F, G))</code> and <code>L(E, F; G)</code></li>
<li>multilinear map, continuous, iso</li>
<li>dual space <code>L(E, R) = E'</code>, functionals on <code>E</code>, it is complete!!! because we are using <code>R</code>!!!</li>
<li><strong>Hahn-Banach</strong>: subspace <code>F</code> of real normed vs <code>E</code>, <code>l: F-&gt;R</code> a functional, then has same bound extension on <code>E</code>
<ul>
<li><em>extension of bounded linear functionals</em></li>
<li>in nvs <code>E</code>, <code>v != 0</code> =&gt; <code>l(v) != 0</code> exists</li>
<li>in <code>C</code> case</li>
</ul></li>
<li>prop 1.3: def <code>f_x: E' -&gt; R or C</code> such that <code>f_x(l) = l(x)</code>, then <code>x-&gt;f_x</code> is injective linear map, norm perserving
<ul>
<li>how to proof <code>|x| &lt; |f_x|</code>? just by reasoning and using HB! and, also, think by a example: the <code>R^2</code></li>
</ul></li>
<li>weak topology on <code>E'</code> is determined by <code>{f_x}</code></li>
<li><strong>Alaoglu’s</strong>: <code>E</code> a Banach space, then <code>E'_1</code> is compact for the weak topology
<ul>
<li><strong>fix me</strong> not understand the proof!</li>
</ul></li>
<li>algebra: vs <code>A</code> &amp;&amp; multiplication: bilinear</li>
<li>normed algebra: associ algebra &amp;&amp; space normed &amp;&amp; <code>|uv| &lt;= |u||v|</code></li>
<li>Banach algebra: normed algebra + complete
<ul>
<li>example: convolution product</li>
<li>cross product in <code>R^3</code> not asso</li>
<li>bounded functions!</li>
</ul></li>
<li>invertible, inverse, unit</li>
<li><code>A</code> Banach algebra with unit <code>e</code>, invertible elems is open in <code>A</code>, and if <code>|v| &lt; 1</code> then <code>e+v</code> is invertible
<ul>
<li><code>u -&gt; u^-1</code> is continuous</li>
<li>toplinear is open in <code>L</code></li>
</ul></li>
<li><code>E</code> nvs, <code>F</code> subspace, <code>G</code> Banach space, continuous linear map <code>l: F -&gt; G</code> has unique linear extension <code>l-bar: F-bar -&gt; G</code> that has same norm</li>
<li>completion of normed vs <code>E</code>: unique exists
<ul>
<li>by <code>E''</code></li>
<li>proof
<ul>
<li>Cauchy seqs <code>S</code></li>
<li>null seqs as subspace</li>
<li>eqvui Cauchy <code>a = b + e</code>, e is null</li>
<li><code>E-bar</code> of equvi class of <code>S</code></li>
<li>norm on <code>E-bar</code></li>
<li>…</li>
</ul></li>
<li>analysis of above one
<ul>
<li>there are totally different elements of same norm!!!</li>
<li>but in our definition, our norm comes from null seq</li>
<li>by this, we can restrict our norm to really say something about nearness…</li>
</ul></li>
<li>in the seminormed form
<ul>
<li>convergence is not unique!</li>
</ul></li>
</ul></li>
<li>operators
<ul>
<li><code>S</code>-invariant subspace</li>
<li><code>B</code> commute with <code>S</code> =&gt; kernel and image is <code>S</code>-inv</li>
<li><code>p -&gt; p(A)</code> is ring homo, for multi params and inv space</li>
<li>direct sum</li>
<li>if <code>A</code> is an operator on <code>E</code>, we are interested to express <code>E</code> as direct sum of <code>A</code>-inv subspaces!</li>
</ul></li>
<li><code>E</code> a vs, <code>E*</code> a vs of linear maps and separate <code>E</code>
<ul>
<li>convex <code>S</code></li>
<li>linear map maps/invs convex to convex</li>
<li>hyperplane</li>
<li>closed half plane</li>
<li>there exists separating hyperplane for convex set and an point not in it</li>
<li>extreme point</li>
<li>1.3 and 1.4</li>
<li><strong>Krein-Milman</strong> context set is unique determined by extremem points</li>
<li><strong>fix me</strong></li>
</ul></li>
</ul>
<h2 id="chapter-04-exercises">chapter 04 EXERCISES</h2>
<ol style="list-style-type: decimal">
<li>..</li>
<li>..</li>
<li>..</li>
</ol>
<h2 id="chapter-05-hilbert-space">chapter 05 Hilbert space</h2>
<p><em>we use vs over <code>C</code>, and assume our product is positive</em></p>
<ul>
<li>antilinear, semi-lienar: <code>l(ax)=a-bar l(x)</code></li>
<li>sesquilinear form, scala product: <code>E*E -&gt; C &lt;x, y&gt;</code> &amp;&amp; linear in <code>x</code> and simi-linear in <code>y</code></li>
<li>hermitian: scala product &amp;&amp; <code>&lt;x,y&gt; = &lt;y,x&gt;-bar</code></li>
<li>positive: hermitian &amp;&amp; <code>&lt;x,x&gt; &gt;= 0</code></li>
<li>positive definite: positive &amp;&amp; <code>&lt;x,x&gt; == 0 &lt;=&gt; x == 0</code></li>
<li>orthogonal: <code>&lt;u,w&gt; = 0</code></li>
<li>null space <code>E_0</code> for hermitian
<ul>
<li><code>&lt;w,w&gt; == 0 =&gt; w in E_0</code></li>
</ul></li>
<li>L^2-norm
<ul>
<li>actually is semi-norm</li>
</ul></li>
<li>Schwarz inquality: <code>|&lt;u, w&gt;| &lt; |v||w|</code></li>
<li>unit vector</li>
<li>has unique <code>c</code>: <code>&lt;v - cw, w&gt; = 0</code> if <code>|w| != 0</code>
<ul>
<li><code>c</code> is Fourier coefficient of <code>v</code> with respect to <code>w</code></li>
<li><code>v</code> perpendicular to <code>v_i</code> when they are mutually perpendicular</li>
<li><code>|w + u| ^2 = |u|^2 + |w|^2</code> when prependicular</li>
<li><code>|w + u| ^2 + |w - u|^2 = 2|w|^2 + 2|u|^2</code></li>
</ul></li>
<li>total family: union of finite generated space is dense in <code>E</code></li>
<li>orthogonal</li>
<li>orthonormal</li>
<li>Hilbert basis: total &amp;&amp; orthnormal family</li>
<li><code>v_i</code> orthognoal, then <code>|x - Sum(c_k v_k)| &lt;= |x - Sum(a_k v_k)|</code></li>
<li>per-Hilbert space: vs &amp;&amp; positive definite hermintian form</li>
<li>Hilbert space: per-Hilbert &amp;&amp; complete under L^2-norm</li>
<li>lemma 1.5: closed subspace of Hilbert space, a point out’s min dis corrpond point in it
<ul>
<li>theorem 1.6 closed subspace has perpenducular point!</li>
<li>exists Hilbert basis</li>
<li><code>E = F + F_|</code></li>
<li>orthogonal projection</li>
<li>1.9: you get a point in generated space of denum <code>F</code> by projections…</li>
<li>orthogonal decomposition</li>
<li>decomposition as in 1.9 and Bessel inqeulity</li>
</ul></li>
<li><code>l_y = &lt;x,y&gt;</code> is functional, <code>y -&gt; l_y</code> is norm-preserving, antilinear isomorphism
<ul>
<li><code>End(E)</code> operators = continuous linear map</li>
<li><code>Herm(E)</code> all continuous hermitian forms</li>
<li><code>Sesqu(E)</code>, continuous sesqu form, <code>Herm</code> is closed in it</li>
<li><code>A -&gt; pi_A</code> is norm perserving isomorphism between <code>End(E)</code> and <code>Sesqu(E)</code></li>
<li>adjoint, transpose <code>&lt;Ax, y&gt; = &lt;x, A*, y&gt;</code></li>
<li>2.3: about the adjoint</li>
<li>sesquilinear form <code>pi</code> then <code>q(x) = pi(x, x)</code> is quadratic form</li>
<li>2.4, complext Hilbert space, <code>&lt;Ax, x&gt; = 0 =&gt; A = O</code>
<ul>
<li>fails in real: rotation</li>
</ul></li>
<li><code>A = A*</code> hermitain, self-adjoint</li>
</ul></li>
</ul>
<h2 id="chapter-05-exercises">chapter 05 EXERCISES</h2>
<h2 id="chapter-06-the-general-integral">chapter 06 the general integral</h2>
<ul>
<li>sigma-algebra, generated sigma-algebra
<ul>
<li>denumerable union &amp; intersection</li>
<li>Borel measureable: generated by open sets</li>
</ul></li>
<li>measurable space, measurable sets</li>
<li>M1,2: measurable function to m-s and t
<ul>
<li>we now assume all of them is using Borel measure</li>
<li>M5: f is measurable to nvs, then <code>|f|</code></li>
</ul></li>
<li>M3: <code>f = (g, h)</code> (<code>f</code> measurable =&gt; <code>g</code>, <code>h</code> measurable) &amp;&amp; (<code>g</code>, <code>h</code> measuralbe &amp;&amp; <code>Y * Z</code>’s open set is union of <code>{O_Y * O_Z}</code>
<ul>
<li>because of M1: satisfied by separatable Banach space</li>
<li>M4: complex function &lt;=&gt; real parts</li>
<li>M6: <code>fg</code> into complex is measurable: using M3 and M1</li>
</ul></li>
<li>M7: <code>f</code> is <code>X</code> into <strong>metric</strong> space, and <code>f_n</code> pointwize convergence to <code>f</code> is measureable, then <code>f</code> is
<ul>
<li>the proof is madness…</li>
</ul></li>
<li>simple map: disjoint finite union of <code>a</code> * ids on measurable sets</li>
<li>M8: finite dimensional &lt;=&gt; pointwize limit of simple maps
<ul>
<li>it constructed it! and very claver, just like dignoziation!</li>
<li>M9: real+, incresing simple maps</li>
</ul></li>
<li>positive measure, <code>u: M -&gt; [0, inf]</code>, countably addtive
<ul>
<li>Dirac measure</li>
<li>counting measure</li>
<li>monotonicity, and union/intersection</li>
<li>1.1, 1,3, 1.2: closed for limit &lt;=&gt; measure
<ul>
<li>countable intersection limit only for <strong>finite</strong>!</li>
</ul></li>
</ul></li>
<li>measured space <code>(X, M, u)</code></li>
<li>almost everywhere, except measure 0</li>
<li>step map: simple &amp;&amp; eauals 0 on infinte measure sets! <code>St(u)</code> of all step maps
<ul>
<li>closed</li>
</ul></li>
<li><code>u</code>-measuralbe: pointwise limit of step maps almost everywhere
<ul>
<li>it is the measure designed for <strong>integral</strong></li>
<li><code>sigma</code>-finite: countable union of finite measure sets</li>
</ul></li>
<li>M10:
<ul>
<li><code>fg</code> with respect to a continuous bilinear map into Banach space
<ul>
<li>complex product</li>
</ul></li>
<li><code>|f|</code></li>
<li><code>1/f</code> for <code>R</code> or <code>C</code></li>
</ul></li>
<li>M11: <code>sigma</code>-measurable &lt;=&gt; exists <code>u(Z) = 0</code> that <code>f|(X-Z)</code> measurable, <code>f</code> vanishs outside a <code>sigma</code>-finite set, and <code>f(X-Z)</code> contains a countable dense set
<ul>
<li>if <code>u</code> is <code>sigma</code>-finite and <code>f</code> into <code>C</code> then only requires <code>f|(X-Z)</code> measurable!</li>
</ul></li>
<li>M12: limit of <code>sigma</code>-measurable is <code>sigma</code>-measureable</li>
<li>so <code>sigma</code>-measurable is preserved under standard ops, without composition</li>
</ul>
<hr />
<ul>
<li><code>f: X -&gt; E</code>, <code>E</code> is a Banach space
<ul>
<li><em>if <code>E</code> is not real or complex valued, then our integral is taking values in Banach space!!!</em></li>
</ul></li>
<li>integral of step functions <code>/_X f du = Sum(mu(A_i)f(A_i))</code>
<ul>
<li><code>/_A f du = /_X f_A du</code></li>
<li>L^1-seminorm <code>||f||_1 = \_X |f| du</code></li>
<li><code>|\_X f du| &lt;= ||f||_1 &lt;= ||f||_sup u(A)</code></li>
</ul></li>
<li><code>L^1</code>-completion <code>St(u) -&gt; L^1(u)</code>
<ul>
<li>this is the equvilence class of Cauchy seq of step functions that convergence under L^1 norm</li>
<li>why we cannot use this definition using null-seq to proof? i think for me, it just means… forget this shit…</li>
<li>there is seq that not Cauchy and diververgence <strong>but</strong> pointwise convergence</li>
</ul></li>
<li>space of L^1-Cauchy seq of step function convering almost everywhere to <code>f</code>: <code>L$^1(u)</code>, is a vs</li>
<li>fundamental lemma of integration: a Cauchy seq of step maps <code>{f_n}</code> has a <strong>subseq</strong> convergence pointwise almost everywhere, and convergence absolutely and uniformly outside any <code>u(Z) &lt; epsilon</code>
<ul>
<li>why subseq? because we are talking about L^1 Cauchy, but not L^1 convergence. <strong>so is this stronger or weaker?</strong> see bellow</li>
<li>lemma 3.2: <code>g_n</code> and <code>h_n</code> Cauchy seq of step maps, convergence almost everywhere to same map, then <code>lim \_X g_n = lim \_X h_n</code> and <code>{g_n - h_n}</code> is null seq</li>
<li>integrable maps : <code>L$^1</code></li>
<li>lemma 3.3 <code>||f||_1</code>d</li>
<li>lemma 3.4 <code>L$</code> is complete</li>
<li><strong>fix me</strong> wtf about this section?</li>
</ul></li>
<li>properties
<ul>
<li>theorem 4.2 <strong>fix me</strong></li>
</ul></li>
<li>lemma 5.1 <code>f in L$^1</code> measurable =&gt; <code>S_c</code> has finite measure, and <code>f</code> vanishes outside a <code>sigma</code>-finite set</li>
<li>theorem 5.2: as 3.1</li>
<li>corollary 5.3 an element <code>f in L$^1</code> has seminorm <code>||f||_1 = 0</code> iff <code>f</code> equal to 0 almost everywhere
<ul>
<li>equivalent in <code>L$^1</code>, the kernel of <code>L$^1 -&gt; L^1</code></li>
</ul></li>
<li>corollary 5.4</li>
<li>theorem 5.5 monotone convergence theorem!</li>
<li>corollary 5.6</li>
<li>corollary 5.7 Fatou’s <code>lim inf f_n</code></li>
<li>theorem 5.8 dominated convergence theorem</li>
<li>corollary 5.9</li>
<li>corollary 5.10</li>
<li>corollary 5.11</li>
<li><strong>fix me</strong></li>
</ul>
<h2 id="chapter-06-exercises">chapter 06 EXERCISES</h2>
<p><strong>fix me</strong></p>
<h2 id="chapter-07-duality-and-representation-theorems">chapter 07 duality and representation theorems</h2>
<h2 id="chapter-07-exercises">chapter 07 EXERCISES</h2>
<h2 id="chapter-08-some-application-of-intergration">chapter 08 some application of intergration</h2>
<h2 id="chapter-08-exercises">chapter 08 EXERCISES</h2>
<h1 id="statistics">statistics</h1>
<p>from the book <em>All of Statistics</em></p>
<p><em>isn’t all problem of statistics can be solved by big data?</em></p>
<h2 id="probability">probability</h2>
<h3 id="formal-definition-in-measure-theory">formal definition in measure theory</h3>
<p><em>i have not read any books about this, but you can get much insight from wikipedia articles</em></p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Random_variable#Measure-theoretic_definition">http://en.wikipedia.org/wiki/Random_variable#Measure-theoretic_definition</a></li>
<li>probability space - measured space with total measure 1</li>
<li>random variable - function from <strong>measured space</strong> to <strong>measurable space</strong>, thus the latter measurable space can get an measure from the preimage
<ul>
<li>so what is a cdf? it is the measure function, so actually <code>R</code> can have various measures</li>
<li>so pdf is not in favour, because it is not a good measure, it only coresponds to <strong>differentiable measure</strong></li>
</ul></li>
<li>conditional - induced normalized measure for subspace</li>
<li><strong>fix me</strong> the conditional and join random variables is not well understood in the perspective now…</li>
</ul>
<h3 id="probability-1">probability</h3>
<ul>
<li>sample space, point: outcome, event, subset: events</li>
<li>probability
<ul>
<li>sigma-algebra, measurable space</li>
<li>non-neg</li>
<li>unity</li>
<li>sigma-additivity</li>
</ul></li>
<li>what it means?
<ul>
<li>freq</li>
<li>Bayesian</li>
<li>in my opinion it do not matters… the model is there, it is just a matter of calculation</li>
<li>but it do lead to different methods</li>
</ul></li>
<li><code>A_n -&gt; A =&gt; P(A_n) -&gt; P(A)</code>: using def, and measure, and properties of limits
<ul>
<li>review: this is the proposition 1 in the positive measure section</li>
</ul></li>
<li><code>P(A|B) = P(AB) / P(B)</code>
<ul>
<li>is this kind of submeasure?</li>
</ul></li>
<li>event independent <code>P(AB) = P(A)P(B)</code>
<ul>
<li><code>P(A|B) = P(A)</code></li>
</ul></li>
<li>Bayes’ theorem <code>P(B) = Sum( P(B|A_i)P(A_i) )</code> is just set ops + simple probobility
<ul>
<li><code>P(A_i|B) = P(B|A_i)P(A_i) / P(B)</code></li>
<li><code>P(A_i)</code> the prior probability of <code>A</code></li>
<li><code>P(A_i|B)</code> the posterior probability of <code>A</code></li>
</ul></li>
</ul>
<h3 id="random-variables">random variables</h3>
<p><em>they are functions on a measure space to R, and you get a measure on R</em></p>
<p><em>the so called multivarance is just linear algebra + rv</em></p>
<p><em>if you do not consider the distribution, then what random <strong>variable</strong> means is that it is normal variables, but you can add them, try to picture youself <code>X-bar/n</code></em></p>
<p><em>join dis is defined by <strong>P</strong>, consider youself the join dis of <code>X</code> and <code>1-X</code>? you cannot picture this! but it do has a cpf! it start at the diag from 0 to 1, but is is not differentable! (what is 2 differentable?)</em></p>
<ul>
<li>random variable <code>X</code>: space to <code>R</code></li>
<li><code>P(X in A) = P(X^-1(A))</code></li>
<li><code>P(X = x) = P(X^-1(x))</code></li>
<li>cumulative distribution function <code>F_X(x): R -&gt; [0, 1] = P(X &lt;= x)</code>
<ul>
<li>theorem 2.7: CDF determines the probability structure
<ul>
<li>review: the induced measure is same! not the rv! for exmaple. <code>f_1 = x</code> and <code>f_2 = -x</code> for a normal</li>
<li>so we must remember that, the function that induced the random variable is always essential</li>
</ul></li>
<li>theorem 2.8: <code>R -&gt; [0,1]</code> is cdf &lt;=&gt;
<ul>
<li>non-decreasing</li>
<li><code>F(-inf) = 0</code> and <code>F(inf) = 1</code></li>
<li><code>F(x) = lim_{y -&gt; x, y &gt; x} F(y)</code>
<ul>
<li>review: this actually concerned with that cdf is defined <code>P(X &lt;= x)</code>, it is a asymetry</li>
</ul></li>
</ul></li>
<li><code>P(X = x) = F(x) - F(x-)</code></li>
<li><code>P(x &lt; X &lt;= y) = F(y) - F(x)</code></li>
</ul></li>
<li>inverse cdf <code>F^-1(q) = inf(x: F(x) &gt; q)</code>
<ul>
<li>if <code>F</code> is strictly increasing and continuous, then it is just function inverse</li>
<li>a simple example: try to picture the inverse of a normal</li>
</ul></li>
<li>probability function <code>f_X(x) = P(X = x)</code></li>
<li>probability density functiion: <code>F_X(x) = integral from -inf to x f_X(t) dt</code>
<ul>
<li>if such a function exists, <code>X</code> is called continuous</li>
<li><code>F</code> is differentiable</li>
<li><code>P(X = x) = 0</code>, this is necessory, because you can using integral!!!</li>
<li>pdf can be unbounded</li>
<li>review: a pdf exists relays on the underline measure space to is differentiable, so it concerns about linearity, so it concerns if it is <code>R</code> or something</li>
</ul></li>
<li>join pf and join cpf
<ul>
<li>consider multivarance normal, so two join has far more different shapes, it is what it means to have a sample space, but when it is independent, we can see it is uniquely defined</li>
<li>independent always means factorable</li>
</ul></li>
<li>pdf of <code>(X, Y)</code></li>
<li>marginal probability function <code>f_X(x)</code>, <code>f_Y(y)</code></li>
<li>marginal cdf <code>F_X</code>, <code>F_Y</code></li>
<li>marginal density <code>f_X(x) = integral f(x, y) dy</code></li>
<li><code>X</code>, <code>Y</code> independent: <code>forall A, B: P(X in A, Y in B) = P(X in A)P(Y in B)</code>
<ul>
<li>for differentialbe &lt;=&gt; <code>f_X,Y = f_X f_Y</code></li>
<li><em>independence of random variable means we can factor the sample space, and reguard the two variable only dependent on one subspace!</em></li>
</ul></li>
<li>conditional pf: <code>f_{X|Y}(x|y) = P(X = x| Y = y)</code> if <code>P(Y = y) &gt; 0</code></li>
<li>conditinal pdf: <code>f_{X|Y}(x|y) = f_{X|Y}(x|y) / f_Y(y)</code>
<ul>
<li><code>P(X in A| Y = y) = integral_A f</code></li>
</ul></li>
<li>tranform random variable, or variables =&gt; variable
<ul>
<li>actually it is always about calculation of a pdf or cdf</li>
</ul></li>
<li>iid sample</li>
</ul>
<h3 id="functional">functional</h3>
<p><em>functionals from the function space to <code>R</code></em></p>
<ul>
<li>median <code>F^-1(1/2)</code></li>
<li><code>E(X) = integral x dF(x) = EX = mu_X</code>
<ul>
<li><em>if you have two variable, you need two integral. thinking the num of rv as the dimension!!! picture youself a multivariance nomral</em></li>
<li>well defined: <code>integral |x| dF(x) &lt; inf</code></li>
<li><code>E(r(X)) = integral r(x) dF(x)</code></li>
<li><code>E(Sum(a_i X_i)) = Sum(a_i E(X_i))</code>
<ul>
<li>dirrectly proofed from lineary of integral, but I need better real analysis</li>
</ul></li>
<li><code>X_i</code> independent =&gt; <code>E(Prod(X_i)) = Prod(X_i)</code>
<ul>
<li>think of integral when id, the integral will be independent</li>
</ul></li>
<li><code>E(a'X) = a'mu</code>, <code>E(AX) = A mu</code></li>
</ul></li>
<li>k-th moment <code>E(X^k)</code>
<ul>
<li>well defined for k</li>
<li>k-th moment exists =&gt; j &lt; k exists</li>
</ul></li>
<li>variance <code>sigma^2 = E(X-mu)^2 = V(X)</code>
<ul>
<li><em>think of a dis, and the mu is a y = mu thing, it will be a lot easy!</em></li>
<li>standard deviation <code>sd(X) = sqrt(V(X)) = sigma</code></li>
<li><code>V(X) = E(X^2) - mu^2</code></li>
<li><code>V(aX+b) = a^2V(X)</code>, obvious when you thinking the line</li>
<li><code>X_i</code> independent =&gt; <code>V(Sum(a_i X_i)) = Sum(a_i^2     V(X_i))</code>, use the same method in expectation</li>
</ul></li>
<li>skewness <code>k = E(X - mu)^3/sigma^3</code></li>
<li>covariance <code>Cov(X, Y) = E((X - mu_X)(Y - mu_Y))</code>
<ul>
<li>corelation <code>rho = Cov(X, Y) / sigma_X sigma_Y</code></li>
<li><code>Cov(X, Y) = E(XY) - E(X)E(Y)</code>
<ul>
<li><em>use the two var thing!!!</em></li>
</ul></li>
<li><code>-1 &lt; rho &lt; 1</code>, expand the integral</li>
<li>when <code>X</code> and <code>Y</code> is linear or independent</li>
<li><code>V(X + Y) = V(X) + V(Y) + 2Cov(X, Y)</code>
<ul>
<li><code>V(Sum(a_i X_i)) = Sum(a_i^2 V(X_1)) + 2 SumSum a_i a_j Cov(X_i, X_j)</code></li>
</ul></li>
<li>variance-covariance matrix <code>Pi</code></li>
<li><code>V(a'X) = a' Pi a</code>, <code>V(AX) = A Pi A'</code></li>
</ul></li>
<li>conditional exception <code>E(X|Y = y) = integral x f dx</code>, <code>E(r(X,Y)| Y = y) = integral r(x, y) f dx</code> is a random variable of <code>y</code>
<ul>
<li>law of total exception: <code>E(E(r(X,Y)| X)) = E(r(X,Y))</code></li>
<li><em>this is a funcional that F(R^2) -&gt; F(R)</em></li>
</ul></li>
<li>conditional variance <code>V(Y|X = x) = integral (y - mu(x))^2 f(y|x) dy</code>
<ul>
<li>law of total: <code>V(Y) = EV(Y|X) + VE(Y|X)</code>
<ul>
<li><em>proof?</em></li>
</ul></li>
</ul></li>
<li>moment generating functions, Laplace transform <code>chi_X(t) : R -&gt; R = E(e^(tX))</code>
<ul>
<li><strong>fix me</strong></li>
</ul></li>
<li><code>X_i</code> idd
<ul>
<li>sample mean <code>X_n-bar = Sum(X_n) / n</code></li>
<li>sample variance <code>S_n^2 = Sum((X_i - X_n-bar)^2) / (n - 1)</code></li>
<li><code>E(X_n-bar) = mu</code></li>
<li><code>V(X_n-bar) = sigma^2 / n</code></li>
<li><code>E(S^2) = sigma^2</code>
<ul>
<li>it means it is unbiased</li>
<li><em>really cmompute this thing! it is easy!</em></li>
</ul></li>
</ul></li>
</ul>
<h3 id="useful-examples-of-rv">useful examples of rv</h3>
<ul>
<li>multivarance normal <strong>fix me</strong></li>
</ul>
<h3 id="inequalities">inequalities</h3>
<ul>
<li>Markov’s: <code>X</code>, <code>t</code> &gt; 0 =&gt; <code>P(X &gt; t) &lt;= E(X) / t</code></li>
<li>Chebyshev’s <code>P(|X-mu| &gt;= t) &lt;= sigma^2 / t^2</code> and <code>P(|(X-mu)/sigma| &gt;= k) &lt;= 1/k^2</code></li>
<li>Hoeffding’s <strong>fix me</strong></li>
<li>Mill’s</li>
<li>Cauchy-Schwartz <code>E|XY| &lt;= sqrt(E(X^2)E(Y^2))</code></li>
<li>Jensen’s <code>g</code> convex =&gt; <code>Eg(X) &gt;= g(EX)</code></li>
</ul>
<h3 id="convergence-of-rv">convergence of rv</h3>
<p><em>they are just normal convergence in functional analysis</em></p>
<p><a href="http://en.wikipedia.org/wiki/Convergence_of_random_variables">http://en.wikipedia.org/wiki/Convergence_of_random_variables</a></p>
<ul>
<li>p: converges in <strong>probability</strong> <code>forall e, P(|X_n - X| &gt; e) -&gt; 0 as n -&gt; 0</code>
<ul>
<li>add, mul, map</li>
</ul></li>
<li>d: converges in <strong>distribution</strong> <code>lim F_n(t) -&gt; F(t)</code>, pointwize
<ul>
<li>const add, const mul, map</li>
</ul></li>
<li>qm: converges in <strong>quadratic mean</strong> <code>E(X_n - X)^2 -&gt; 0</code>
<ul>
<li>add</li>
</ul></li>
<li>qm =&gt; p =&gt; d
<ul>
<li>special case: point mass d &lt;=&gt; p</li>
</ul></li>
<li>weak law of large numbers: <code>X_n-bar -P-&gt; mu</code></li>
<li>clt: <code>Z_n = (X_n-bar - mu)/sqrt(V(X_n-bar)) = sqrt(n)(X_n-bar - mu)/sigma -d-&gt; N(0, 1)</code>
<ul>
<li>variance -&gt; sample variance is ok</li>
<li>multivariate version <code>sqrt(n)(X-bar - mu) -d-&gt; N(0, Pi)</code></li>
<li>delta method: <code>sqrt(n)(Y_n - mu) / sigma -d-&gt; N(0, 1)</code> &amp;&amp; <code>g</code> differentiable and <code>g'(mu) != 0</code> =&gt; <code>g(Y_n) -d-&gt; N(g(mu)</code>, <code>g'(mu)^2 * sigma^2 / n)</code>
<ul>
<li>multivariate delta method <strong>fix me</strong></li>
</ul></li>
</ul></li>
</ul>
<h2 id="stochastic-process">stochastic process</h2>
<ul>
<li>stochastic process, state space, index set</li>
<li>Markov chain <code>f(x_1,...,x_n) = f(x_1)f(x_2|x_1)...</code>
<ul>
<li>qestions
<ul>
<li>when settle down</li>
<li>parameter estimate</li>
<li>how to construct to converge</li>
</ul></li>
</ul></li>
<li>homogeneous
<ul>
<li>transition probabilities, transition matrix</li>
<li><code>p_ij(n)</code> n-step transition probabilities
<ul>
<li><code>p_ij(m + n) = Sum( p_ik(m) + p_kj(n) )</code></li>
</ul></li>
<li>simulation, <code>mu_0</code> initial distribution
<ul>
<li><code>mu_n = m_0 P^n</code></li>
</ul></li>
<li>reaches, communicate (is a equvilent)</li>
<li>irreducible, closed states, absorbing state</li>
<li>recurrent = persistent, transient
<ul>
<li>recurrent &lt;=&gt; <code>Sum (p_ii (n)) = Inf</code></li>
<li>communicate preserve recurrent and transient</li>
<li>finite Markov chain must has one recurrent state, if it is irreducible, all state is recurrent (simple)</li>
</ul></li>
<li>decomposition theorem: state space <code>X = X_T \/ X_i</code>, <code>X_T</code> is trans, <code>X_i</code> is irreducible recurrent (just use partition)</li>
<li>recurrent time (a rv): <code>T_ij = min{n | X_n = j}</code>
<ul>
<li>mean recurrent time <code>m_i = E(T_ii) = Sum(n f_ii(n))</code></li>
</ul></li>
<li>null, positive recurrent state
<ul>
<li>null -&gt; <code>p_ii(n) -&gt; 0</code></li>
<li>finite state -&gt; all positive</li>
</ul></li>
<li>period <code>d = gcd{n|p_ii(n) &gt; 0}</code>
<ul>
<li>periodic: <code>d &gt; 1</code></li>
<li>aperiodic: <code>d = 1</code></li>
</ul></li>
<li>ergodic = recurrent &amp; positive &amp; aperiodic (state | chain)
<ul>
<li>e.g. <em>23.28 Example</em></li>
</ul></li>
<li>stationary = invariant
<ul>
<li>stationary not necessory to converge!!!</li>
</ul></li>
<li>limitint distribution <code>P^n -&gt; [pi; pi; pi; ...]</code>, here <code>pi</code> is a vector!!!</li>
<li>irreducible, ergogic Markov chain has unique stationary distribution <code>pi</code>, limiting distribution is also <code>pi</code>, <code>g</code> bounded =&gt; <code>lim_N Sum(g(X_n))/N -&gt; E_pi(g) = Sum(g(j) pi)</code></li>
<li>detailed balance <code>pi_i p_ij = p_ji pi_j</code>
<ul>
<li>detailed balance =&gt; stationary distribution</li>
</ul></li>
<li><strong>fix me</strong> 23.31</li>
</ul></li>
<li>Possion processes <strong>fix me</strong></li>
</ul>
<h2 id="statistical-inference">statistical inference</h2>
<p><em>statistical inference is not solving equtions, because you have noise, you cannot get exact input/output, and so nomrally your knowns is not the degree of freedom of the system!!! and you do not solve exactly!!! they are not same problem at all!!!</em></p>
<h3 id="statistical-inference-1">statistical inference</h3>
<p><em>theory of inference</em></p>
<ul>
<li>kinds of inference model: given <code>X_i</code> the sample rv
<ul>
<li>non-parametric model
<ul>
<li><code>F</code></li>
<li><code>E(X)</code> - this is of course simpler, because we applied a very concentrating function</li>
<li>…</li>
</ul></li>
<li>parametric model
<ul>
<li><code>paramemters</code> - same as <code>F</code>, because we have a smaller search space for <code>F</code> for we have <strong>constrains</strong>, so we have a function to map parameters to <code>F</code>s</li>
<li>sometimes we estimate functional of estimators…, mostly <code>E</code> and <code>V</code></li>
</ul></li>
</ul></li>
<li>statistical model, parametric model, parameter space, nuisance parameters</li>
<li>predictor = regressor = feature = independent variable, outcome = response = dependent v</li>
<li>parameter regression model, nonparametric regression model (infinite-dim regression), prediction, classification, regression = curve estimation</li>
<li>freq inference, Bayesian inference</li>
<li>point estimation <code>theta_n-head = g(X_1,...,X_n)</code> for some <code>g</code> is a random variable
<ul>
<li><code>bias(theta_n-head) = E_theta(theta_n-head) - theta</code>, unbiased
<ul>
<li>this is a scalar, it is a statistical functional applied to a rv, so a saclar!!!</li>
</ul></li>
<li>consistent <code>-p-&gt;</code></li>
<li>sample distribution</li>
<li>standard error <code>se = sqrt(V(theta_n-head))</code> is applied value! again a salar!</li>
<li>ese <code>se-head</code></li>
<li>6.8 - see a worked out example for Bernoulli!
<ul>
<li>when calculating <code>V(p^n)</code>, use <code>X^2</code> and independence expansion!</li>
</ul></li>
<li><code>MSE = E(theta^_n - theta)^2 = bias^2 + V_theta</code>
<ul>
<li>this is not the variance of <code>theta^_n</code>! this is only true when you are unbias!!!</li>
</ul></li>
<li>e.g
<ul>
<li>parameter</li>
<li>cdf</li>
<li>pdf</li>
</ul></li>
<li><code>bias -&gt; 0 &amp;&amp; se -&gt; 0 =&gt; MSE -&gt; 0 =&gt; -pm-&gt; =&gt; -p-&gt;</code></li>
<li>asymptotically normal <code>(theta_n-head - theta) / se -&gt; N(0, 1)</code></li>
</ul></li>
<li><code>1-a</code> confidence interval <code>P(theta in C_n) &gt;= 1-a</code>, <code>C_n</code> is<code>(a(X_1,...,X_n), b(...))</code> is a <strong>random variable</strong>!!
<ul>
<li>confidence set: when multivariance</li>
<li>normal-based confidence interval <em>p94</em>
<ul>
<li>comparing 6.17 and 6.15, notice that normal-based only has large approximately correct coverage</li>
</ul></li>
</ul></li>
<li>hypothesis testing</li>
</ul>
<h3 id="nonparameter-mentods-for-cdf-and-functionals">nonparameter mentods for cdf and functionals</h3>
<p><em>I think we have enough error terms to do this! namely the convergence and bias!</em></p>
<ul>
<li>empirical distribution function <code>F_n-head(x)</code> it is <code>R -&gt; F(R)</code>, given a <code>x</code> it has a estimation of the value at this <code>x</code>
<ul>
<li>at <code>x</code>
<ul>
<li><code>E(F-head) = F(x)</code>, is unbiased</li>
<li><code>MSE = V(F-head) = F(x)(1-F(x)) / n</code></li>
<li><code>F_n-head(x) -P-&gt; F(x)</code>, it is consistant</li>
</ul></li>
<li><code>sup_x |F_n-head(x) - F(x)| -P-&gt; 0</code>
<ul>
<li><code>F^_n</code> give the function space a measure, and sup translate this measure again into scalar, and it is porobility limit to 0
<ul>
<li>DKW inequality <strong>fix me</strong></li>
</ul></li>
<li>confidence interval based on DKW</li>
</ul></li>
</ul></li>
<li>plug-in estimator of statistical functional <code>T(F)</code>: <code>theta_n-head = T(F_n-head)</code>, a functional is takes a rv to value, then you plugin to get a rv again!!!
<ul>
<li>lienar functional <code>T(F) = integral r(x) d F(x)</code>, <code>T</code> is linear in arguments!</li>
<li>plug-in estimator for linear funtional <code>T(F_n-head) = Sum(r(X_i)) / n</code> is a rv!</li>
<li>and we want <code>se</code> for this rv…</li>
<li>in many cases… <code>T(F_n-head) ~ N(T(F), se-head^2)</code>, means that we have a good enough estimator! and how to understand right??? you should divide to the left youself!!!</li>
<li>then <code>1-a</code> ci is <code>T(F_n-head) +- z_{a/2} se-head</code></li>
<li>e.g. it is just crazy… everything is rv!
<ul>
<li>mean - estimator, se-estimator, confidence interval</li>
<li>variance - plugin, sample variance <code>S^2_n</code></li>
<li>skewness</li>
<li>correlation - sample corelation</li>
<li><em>7.15</em></li>
</ul></li>
<li>in paramter model, we has formula for errors, but in nonparamter model, we mostly use bootstrap method</li>
</ul></li>
</ul>
<h3 id="bootstrap-method">bootstrap method</h3>
<p><em>in essence, bootstrap is just like plugin methods</em></p>
<ul>
<li>step
<ol style="list-style-type: decimal">
<li>estimate <code>V_F(T_n)</code> by <code>V_F^(T_n)</code>: if we can stop here, it is just plugin method</li>
<li>approximate <code>V_F^(T_n)</code> by simulation</li>
</ol></li>
<li>illu
<ul>
<li>real world <code>F</code> =&gt; <code>X_i</code> =&gt; <code>T_n</code></li>
<li>bootstrap world <code>F^_n</code> =&gt; <code>X*_i</code> =&gt; <code>T*_n</code></li>
</ul></li>
</ul>
<p><strong>fix me</strong></p>
<h3 id="parametric-inference">parametric inference</h3>
<p><em>if the world is a determined world, there is no noise at all, noise exists, is because our model is problamic or there is other things, but we think them as random</em></p>
<ul>
<li>the method of moments, assume <code>theta = (theta_1,..., theta_k)</code>
<ul>
<li>moment <code>a_j = a_j(theta) = integral x^j d F_theta(x)</code>, note that it is an function of theta, because we are having unknown theta</li>
<li>sample moment <code>a_j-head = Sum(X_i^j) / n</code></li>
<li>method: <code>forall j in 1 -&gt; k: a_(theta_n-head) = a_j-head</code>, it has <code>k</code> unknown of rvs, and we can solve for to get the estimator</li>
<li>properties
<ul>
<li>exits with probability tending 1</li>
<li>consistent</li>
<li>asympototically normal</li>
</ul></li>
<li><strong>fix me</strong> not well understood</li>
</ul></li>
<li>maximum likelihood method
<ul>
<li><em>most of the things bellow is from information theory!!!! so read them when have time!!!</em></li>
<li>likelihood function <code>L_n(theta) = Prod(f(X_i; theta))</code>, log-likelihood funtion <code>l_n(theta) = log(L_n(theta))</code>. give a param, get a rv</li>
<li>method: the thet a maximaze it! using derivative! you get an estimator!</li>
<li>multivar: we need global maxima, can use partial to find</li>
<li>properties (under certain regularity conditions of the model, rf <a href="http://en.wikipedia.org/wiki/Maximum_likelihood">http://en.wikipedia.org/wiki/Maximum_likelihood</a>)
<ul>
<li>consistent
<ul>
<li>Kullback-Leibler distance, information gain</li>
<li>first proof <code>M_n</code> converge to <code>-D(theta*, theta)</code>, if convergence is uniform over <code>theta</code>, then we can proof <code>theta^_n -p-&gt; theta*</code></li>
</ul></li>
<li>equivariant <code>g(theta)</code></li>
<li>asymptotically normal
<ul>
<li>score function <code>s(X;theta) = &amp; log f(X; theta) / &amp; theta</code></li>
<li>Fisher information <code>I_n(theta) = Sum( V_theta(s(X_i; theta)) )</code></li>
<li><code>I_n(theata) = nI(theta)</code></li>
<li><code>I(theta) = E_theta(-s')</code></li>
<li><code>se = sqrt(1/I_n(theta))</code></li>
<li><code>se^</code></li>
<li><code>(theta^_n - theta) /  se^ -d-&gt; N(0, 1)</code></li>
<li>asymptotic confidence interval</li>
</ul></li>
<li>asymptotically optimal: for large example, has smallest variance
<ul>
<li>see exercise 2</li>
</ul></li>
<li>delta method
<ul>
<li>the distribution is also equivariant, so interval</li>
</ul></li>
<li>approximately the Bayes estimator</li>
</ul></li>
<li>multiparameter method <strong>fix me</strong></li>
<li>parametric bootstrap method</li>
<li>numerical methods
<ul>
<li>Newton-Raphson</li>
<li>EM algorithm
<ul>
<li>hidden variable</li>
<li>maxiture of two normals</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="hypothesis-testing">hypothesis testing</h3>
<ul>
<li>we patition the parameter space into <code>Theata_0</code> and <code>Theata_1</code></li>
<li><code>H_0: theta in Theta_0</code> null hypothesis, and alternative hypothesis</li>
<li>rejection region <code>R</code>, <code>X</code> be a rv and <code>R &lt; Dom(X)</code>, we calculate a rv, and see if we reject the null hypothesis
<ul>
<li>it is normally form <code>R = {x: T(x) &gt; c}</code></li>
<li>test statistic, critical value</li>
</ul></li>
<li>type 1, 2 error</li>
<li>power function, size, level</li>
<li>simple hypothesis, composite hypothesis, two-sided test, one-sided test</li>
<li>Wald test <strong>see book</strong></li>
<li>p-value = <code>inf {a: T(X^n) in R_a}</code>, smallest level we can reject <code>H_0</code>
<ul>
<li>large p-value can occur in two reason: true or test has low power!</li>
</ul></li>
<li><strong>fix me</strong></li>
</ul>
<h3 id="bayesian-inference">Bayesian inference</h3>
<ul>
<li>Bayes theorem <code>f(theta|x) =   f(x|theta)f(theta) / integral f(x|theta) f(theta) d theta</code></li>
<li><code>f(theta|x^n) = L_n(theta)f(theta) / c_n</code></li>
<li>conjugate with model</li>
<li><strong>fix me</strong></li>
<li>what prior to use?
<ul>
<li>..</li>
</ul></li>
<li><strong>fix me</strong></li>
</ul>
<h3 id="dicision-theory">dicision theory</h3>
<p><em>how to? is it not just calculate the estimated error?</em></p>
<ul>
<li>how to choose estimator: decision theory</li>
<li>decision rule = estimator, action = values of estimator</li>
<li>loss function</li>
<li>risk <code>R(theta, theta-head)</code>
<ul>
<li>e.g. when you are using squared error… the risk is just mse!!!</li>
<li>maximum risk <code>R-bar(theta-head)</code></li>
<li>Bayes risk <code>r(f, theta-head)</code></li>
</ul></li>
<li>Bayes rule, minimax ruleok</li>
<li><strong>fix me</strong></li>
</ul>
<h2 id="models-and-methods">models and methods</h2>
<h3 id="linear-and-logistic-regression">linear and logistic regression</h3>
<ul>
<li>regression fuction <code>r(x) = b_0 + b_1 x</code></li>
<li>assuming <code>V(e_i|X = x) = sigma^2</code> do not depend on <code>x</code></li>
<li><code>Y_i = b_0 + b_1 X_i + e_i</code>, <code>E(e_i|X_i) = 0</code>
<ul>
<li><code>sigma</code> is also a paramter of the model!</li>
<li>fitted line <code>r-head(x) = b_0-head + b_1-head x</code></li>
<li>fitted values <code>Y_i-head = r-head(X_i)</code></li>
<li>residuals <code>e_i-head = Y_i - Y_i-head</code></li>
<li>residual sums of squares <code>RSS = Sum ( e_i-head ^2 )</code></li>
<li>least square estimates: minimize rss, calculate them using dervi!
<ul>
<li><code>b_1-head = Sum( (X_i - X_n-bar)(Y_i - Y_n-bar) ) / Sum( (X_n - X_n-bar)^2 )</code></li>
<li><code>b_0-head = Y_n-head - b_1-head X_n-bar</code></li>
<li><code>sigma^2-head = RSS / (n - 2)</code></li>
<li><code>E(b-head|X^n) = (b_0; b_1)</code> this is a constant function of <code>X^n</code></li>
<li><code>V(b-head|X^n) =</code> see the book, this means if you pick <code>x</code>s too close, you will have a very bad estimate</li>
<li><code>se-head(b_0|X^n)</code> and <code>se-head(b_1|X^n)</code></li>
<li>consistant</li>
<li>asymptotic normality</li>
<li>approximate <code>1-a</code> interval is <strong>see book</strong></li>
<li>Wald test</li>
</ul></li>
<li>under normal assumption, lse is mle</li>
<li>prediction interval <strong>fix me</strong></li>
<li>multiple regression
<ul>
<li><em>the model assumed when we know we are sampling from independent <code>x</code>s!!!!</em></li>
</ul></li>
<li>model selection, overfitting, underfitting
<ul>
<li>prediction risk, training error</li>
<li><code>C_p</code> statistic</li>
<li><strong>fix me</strong></li>
</ul></li>
</ul></li>
<li>logistic regression</li>
</ul>
<h3 id="multivariate-models">multivariate models</h3>
<h3 id="inference-about-independence">inference about independence</h3>
<h3 id="causal-inference">causal inference</h3>
<h3 id="directed-graphs">directed graphs</h3>
<h3 id="undirected-graphs">undirected graphs</h3>
<h3 id="log-linear">log-linear</h3>
<h3 id="nonparametric-curve-estimation">nonparametric curve estimation</h3>
<h3 id="smoothing-using-orthogonal-functions">smoothing using orthogonal functions</h3>
<h3 id="classification">classification</h3>
<ul>
<li>classification = pattern recognition
<ul>
<li>the estimation process is learning!</li>
</ul></li>
<li>input <code>X_i = (X_i1,..., X_id) in R^d</code> is a n number of d-dim input, find <code>h(R^d) -&gt;</code></li>
<li>true error rate <code>L(h) = P(h(X) != Y)</code></li>
<li>eer <code>L_n-head(h) = Sum(I(h(X_i) != Y_i)) / n</code></li>
<li>regression function <code>r(x) = P(Y = 1| X = x)</code>
<ul>
<li><em>it is a probability, because there might be other DOF in the model!!!</em></li>
</ul></li>
<li>Bayes classification rule <code>h* = 1 if r(x) &gt; 1/2</code></li>
<li>multi version <code>h(x) = argmax_k P(Y = k|X = x)</code>
<ul>
<li><code>P(Y = k|X = x) = f_k(x)pi_k / Sum( f_i(x)pi_i )</code></li>
<li><code>pi_i = P(Y = i)</code>, <code>f_i(x) = f(x|Y = i)</code></li>
</ul></li>
<li>ways?
<ul>
<li>empirical risk mini</li>
<li>regression</li>
<li>density estimation</li>
</ul></li>
<li>Gaussian classifiers
<ul>
<li>assume both are multivariate Gaussian <strong>see book</strong></li>
<li><code>h*(x) = argmax_k( -1/2*log|Pi_k| - 1/2*(x-mu_k)'Pi_k^-1(x-mu_k) + log pi_k )</code></li>
<li>sample esimates</li>
<li>qda</li>
<li>simplification when <code>Pi_1 = Pi_0</code> <strong>fix me</strong>, lda</li>
<li>Fisher lienar discrimination</li>
</ul></li>
<li>linear regression: model the <code>r(x)</code> using a linear function!!!
<ul>
<li>relationship logi stic and lda
<ul>
<li>parameters estimation!
<ul>
<li>lr: discriminative learning</li>
<li>lda: generative learning</li>
</ul></li>
</ul></li>
</ul></li>
<li>density estimation and naive Bayes</li>
</ul>
<h3 id="simulation-methods">simulation methods</h3>
<ul>
<li>Monte Carlo integration</li>
<li>Metropolis-Hastings algorithm</li>
<li>Gibbs sampling</li>
</ul>
<h2 id="references-5">references</h2>
<h1 id="information-theory">information theory</h1>
<p>from the book <em>Elements of Information Theory</em></p>
<h2 id="preview">preview</h2>
<ul>
<li>entropy of rv <code>H(X) = -Sum(p(x) lg p(x))</code></li>
<li>mutual information <code>I(X;Y) = H(X) - H(X|Y) = Sum(p(x, y) lg(p(x, y)/p(x)p(y)))</code></li>
<li>communication channel, probability transition matrix <code>p(y|x)</code>
<ul>
<li>capacity <code>C = max_{p(x)} I(X;Y)</code></li>
<li>e.g. noisy four-symbol channel</li>
</ul></li>
<li>relative entropy <code>D(p||q)  = Sum(p(x) lg (p(x)/q(x)))</code></li>
</ul>
<h2 id="basics">basics</h2>
<ul>
<li>conditional entropy</li>
<li>chain rule</li>
</ul>
<h1 id="mathematical-optimization">mathematical optimization</h1>
<p>from <em>Convex Optimization</em> slides by Stephen Boyd, Wikipedia, etc.</p>
<h2 id="refs">refs</h2>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Mathematical_optimization">http://en.wikipedia.org/wiki/Mathematical_optimization</a></li>
<li><a href="http://en.wikipedia.org/wiki/Hessian_matrix">http://en.wikipedia.org/wiki/Hessian_matrix</a></li>
<li>maximum likelihood for point esitimation… the <span class="math">\(f\)</span> in it is the pdf… so it is resonable to assume the maximum… but in nn, we do not have this shit… and in linear regression, we have <strong>conditional likelihood</strong></li>
</ul>
<h2 id="ideas">ideas</h2>
<ul>
<li>what about mix them?</li>
<li>what about start multi place, and discard on the way?</li>
</ul>
<h2 id="defs">defs</h2>
<ul>
<li>mathematical optimization problems: <span class="math">\(max\)</span>
<ul>
<li>maybe we should say that “computational” but not “symbolic”</li>
</ul></li>
<li>objective function = cost function = loss function</li>
<li>order of approximation: order of magnitude of the error is <span class="math">\(O\left(x^{n+1}\right)\)</span>
<ul>
<li>in suitable case, expand by Taylor is ok</li>
</ul></li>
</ul>
<h2 id="methods">methods</h2>
<h3 id="nonlinear-programming">nonlinear programming</h3>
<p><span class="math">\[y = f(x + \Delta x) \approx f(x) + J(x)\Delta x + \frac{1}{2} \Delta x ^T H(x) \Delta x\]</span></p>
<!--- should go to calculus one day --->

<p>differ by how to eval Hessian, gradients</p>
<ul>
<li>Newton’s method: eval the Hessian, ie, find zero in the driv</li>
<li>methods evaluate gradients or approximate gradients
<ul>
<li>quzsi-Newton
<ul>
<li>L-BFGS</li>
</ul></li>
<li>gradient descent</li>
<li>conjugate gradients</li>
<li>variable metric methods</li>
</ul></li>
</ul>
<h2 id="references-6">references</h2>
<h1 id="problem-solving">problem solving</h1>
<h2 id="pages">pages</h2>
<ul>
<li><a href="http://terrytao.wordpress.com/career-advice/solving-mathematical-problems/">http://terrytao.wordpress.com/career-advice/solving-mathematical-problems/</a></li>
<li><a href="http://terrytao.wordpress.com/career-advice/there%E2%80%99s-more-to-mathematics-than-grades-and-exams-and-methods/">http://terrytao.wordpress.com/career-advice/there%E2%80%99s-more-to-mathematics-than-grades-and-exams-and-methods/</a></li>
<li><a href="http://terrytao.wordpress.com/2010/10/21/245a-problem-solving-strategies/">http://terrytao.wordpress.com/2010/10/21/245a-problem-solving-strategies/</a></li>
<li><a href="https://plus.google.com/u/0/114134834346472219368/posts/Xdm8eiPLWZp">https://plus.google.com/u/0/114134834346472219368/posts/Xdm8eiPLWZp</a>
<ul>
<li><em>The point is that even if the technique is doomed to fail, the precise point in the argument at which it fails can be very instructive, as it can delineate what portion of the problem can be handled</em></li>
</ul></li>
<li><a href="http://terrytao.wordpress.com/career-advice/ask-yourself-dumb-questions-%E2%80%93-and-answer-them/">http://terrytao.wordpress.com/career-advice/ask-yourself-dumb-questions-%E2%80%93-and-answer-them/</a>
<ul>
<li><em>Don’t just read it; fight it! Ask your own questions, look for your own examples, discover your own proofs. Is the hypothesis necessary? Is the converse true? What happens in the classical special case? What about the degenerate cases? Where does the proof use the hypothesis?</em></li>
</ul></li>
</ul>
<h1 id="random-puzzles">random puzzles</h1>
<ul>
<li><a href="https://www.quantnet.com/threads/jane-street-interview-question-needing-help.7591/">the noodles probability</a> * consider the first pick</li>
<li><a href="https://www.quantnet.com/threads/jane-street-interview-question-needing-help.7591/">100 dice problem!</a> * consider the position <span class="math">\((n, m)\)</span> * from the above two, we can see that you should know where to start considering the problem</li>
<li>the <span class="math">\(n\)</span> man remember card problem * it is not clear at all when considering this point, but you should consider the optimal solution when go on</li>
<li>the gate program: can you make a circuit calculate the not of 3 variables using only 2 <code>not</code> gate and arbitrary <code>and</code> and <code>or</code> gates? * boolean function reduction! then you have a function that has no <code>not</code> in it!</li>
<li>the two kid cake problem * it is a optimization problem! <code>minimize[ max(max(1-x,x), min(1-x,x)+1/2) ]</code> * but in a more general form <code>min(1 - max( max(1-x1,x1) + min(1-x2, x2), min(1-x1,x1) + max(1-x2, x2) ) )</code> * if 3 cake, the same problem!!! <code>minimize[ max_first, max_second, max_last ]</code> * for the general case, we need * first, we need to know it has a <strong>eq point</strong> * then we find it like above!</li>
<li>proof that you have <span class="math">\(n+1\)</span> integers bellow <span class="math">\(2n\)</span>, always two relatively prime * this takes Erdios 10 minutes</li>
</ul>
    </div>
</div>

</div>
<script src="./js/jquery.toc.js"></script>
<script src="./js/toc.js"></script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  </div>

    <div class="footer">
      <div class="container">
        <span></span>
      </div>
    </div>

      <script src="./js/bootstrap.min.js"></script>
    </body>
</html>
